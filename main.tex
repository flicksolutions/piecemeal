\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{csquotes}
\usepackage[ngerman=ngerman-x-latest]{hyphsubst}
\usepackage{color} %Zum stylen von \def
\usepackage[dvipsnames]{xcolor}
\usepackage{varwidth} %Zum stylen von \def
\usepackage{etoolbox} %Zum stylen von \def
\usepackage{amssymb} %Für die Mengensymbole
%\usepackage{svg}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{amsmath} %Zur Darstellung von Funktionen mit Fallunterscheidung
\usepackage{scrlayer-scrpage} %Kopf- und Fusszeile
\usepackage{titling} %Titel nach oben verschieben
\usepackage{amsfonts} %\mathcal
\usepackage{enumerate} %Für kleine römische Zahlen in Aufzählungen
\usepackage{hyperref}
\usepackage[normalem]{ulem} %für durchgestrichenen text
\newcommand{\stkout}[1]{\ifmmode\text{\sout{\ensuremath{#1}}}\else\sout{#1}\fi} %text durchstreichen auch in math-mode

\usepackage[
backend=biber,
style=apa,
]{biblatex}
%\usepackage[style=authoryear]{biblatex}
\addbibresource{references.bib}


\definecolor{teal}{RGB}{124,214,253}
\definecolor{blue}{RGB}{94,100,255}
\definecolor{purple}{RGB}{116,62,226}

%% Formatierung %%
\sloppy
\usepackage[dvipdfm]{geometry}
\setlength{\droptitle}{-10em}
\geometry{bottom=3.5cm, textwidth=15cm, headsep=15mm, top=5cm,head=15pt}
%%%%%%%%%%%%%%%%%%

%%  Kopf- und Fusszeile anpassen %%
\pagestyle{scrheadings} 

\ihead{\small{Bachelorarbeit}}
\ohead{\small{Sebastian Flick, Universität Bern}}
\cfoot{\thepage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setlength{\marginparwidth}{2cm}

%%%%%%%%%%%%%%%%%%%%


\title{Ein realistischeres Modell des Überlegungsgleichgewichts}
\author{Bachelorarbeit von Sebastian Flick, 16-121-014\\Betreut von Prof. Dr. Dr. Claus Beisbart\\Universität Bern}


\date{\today}

\begin{document}
\maketitle
\section{Einführung}
In dieser Arbeit geht es um ein Modell, welches das Überlegungsgleichgewicht umsetzt. Für diese Methode zur Rechtfertigung, welche seit den Siebzigerjahren des letzten Jahrhunderts von vielen Philosophen und Philosophinnen vertreten und von ähnlich vielen kritisiert wurde, entwickelten \cite{beisbart_making_2021} ein exaktes Modell.
Das Ziel der vorliegenden Arbeit ist es, innerhalb dieses Modells einen kleinen, aber wichtigen Aspekt zu untersuchen: die Theorie- und Überzeugungsanpassung. Konkret soll ein Piecemeal-Ansatz formuliert werden. Dieser soll die gegenseitige Anpassung von Überzeugungen und Theorien besser umsetzbar und einfacher nachvollziehbar gestalten. Um herauszufinden, wie Theorien und Überzeugungen in den jeweiligen Anpassungsschritten angeglichen werden müssen, wird bisher jede mögliche und konsistente Kombination von Prinzipien und Überzeugungen überprüft. Dies ist einerseits nicht, was \citeauthor{goodman_fact_1983} im Sinn hatte, als er Reflective Equilibrium beschrieb -- er sprach von einzelnen Sätzen, welche zur Theorie bzw. zu den Überzeugungen addiert oder subtrahiert würden \parencite[vgl.][]{goodman_fact_1983} -- andererseits ist dieses Vorgehen ab einer gewissen Grösse des zu behandelnden Themas schlicht nicht umsetzbar. Ausserdem ist es wichtig, einen intuitiven Weg zu finden, wie die Änderungen an Theorie und Überzeugungen gemacht werden -- denn auch von diesem Faktor hängt die Glaubwürdigkeit der Methode ab. Eine mögliche Antwort auf diese Herausforderungen ist ein Piecemeal-Ansatz, welcher Überzeugungen und Prinzipien stückweise zu vorhanden Überzeugungen und Theorien hinzufügt oder von dieses entfernt. Ziel dieser Arbeit ist es, eine konkrete Formulierung eines solchen Piecemeal-Ansatzes zu finden. Wenn im Rahmen dieser Arbeit von einem Piecemeal-Ansatz die Rede ist, ist mein ausformulierter Ansatz gemeint. Um herauszufinden, ob sich die Anwendung des Piecemeal-Ansatzes lohnt, habe ich eine Ensemblestudie generiert und die vorhandenen Daten analysiert. Dies, um zu verstehen, unter welchen Bedingungen der Piecemeal-Ansatz tatsächlich besser ist als der traditionelle Ansatz. Ausserdem stiess ich mithilfe der Ensemblestudie auf zwei Aspekte, die ich an der Umsetzung des Modells in ein Programm bzw. an der Gewichtung der Desiderata ändern würde.

Ich werde zu Beginn der Arbeit die Methode Reflective Equilibrium vorstellen und eine kleine historische Einführung in das Thema geben. Danach werde ich den Piecemeal-Ansatz detailliert vorstellen. Ich werde ihn innerhalb des Modells von \citeauthor{beisbart_making_2021} definieren und zeigen, dass der Ansatz unter bestimmten Bedingungen besser ist als der konventionelle, aber auch ein grosses Problem hat. Dann werde ich zur Ensemblestudie übergehen und eine Übersicht geben, bevor ich zum Schluss auf die entdeckten Unstimmigkeiten eingehe.

\section{Reflective Equilibrium und seine Ursprünge}

Bei Reflective Equilibrium handelt es sich um eine Methode zur Rechtfertigung unserer Überzeugungen. Sie ist als Instrument zu verstehen, um zu einer gerechtfertigten Meinung zu kommen. Wir pflegen unsere anfänglichen Überzeugungen -- die eine gewisse anfängliche Glaubwürdigkeit haben -- in ein System von Prinzipien ein und passen beide aneinander an. Am Ende dieses Anpassungsprozesses erhalten wir einen Gleichgewichtszustand. Aus dem System von Prinzipien folgen unsere Überzeugungen, die wir anfangs für plausibel hielten. Dadurch ist die Überzeugung gerechtfertigt. Es gibt verschiedene Auffassungen darüber, wie Reflective Equilibrium funktioniert -- oder funktionieren soll -- und wie es zu verstehen ist \parencite{sep-reflective-equilibrium}.
Ich werde mich in dieser Arbeit aber an die von \cite{beisbart_making_2021} vertretene Interpretation halten. Dies beinhaltet, dass Reflective Equilibrium -- wie eingangs beschrieben -- zur Beantwortung von Fragen in einem Gebiet eingesetzt werden kann und somit nach \citeauthor{freeman_rawls_2002} deliberativ ist. Eine rein deskriptive Auffassung, bei welcher durch das Reflective Equilibrium lediglich herausgefunden werden kann, welche Überzeugungen eine Person hat, wird hier nicht weiterverfolgt. \parencite[vgl.][S.~143]{freeman_rawls_2002}

Für Scanlon ist der Prozess kein rein quantitatives Unterfangen. Das Individuum, welches einen RE-Prozess durchführt, merkt beispielsweise, durch welche Prinzipien seine Überzeugung gestützt wird und kann sich dann spontan auf Basis von beispielsweise politischen oder inhaltlichen Überlegungen dazu entscheiden, die Überzeugung aufzugeben. Für \citeauthor{freeman_rawls_2002} ist somit ausgeschlossen, dass der Prozess durch ein mathematisches Modell abgebildet werden kann. \parencite[vgl.][S.~148]{freeman_rawls_2002}
Eine weitere Distinktion zwischen den verschiedenen Interpretationen von Reflective Equilibrium ist die Unterscheidung zwischen \textit{wide} (breit) und \textit{narrow} (schmal) Reflective Equilibrium: Diese wurde von \cite{daniels_wide_1996} eingeführt. Das Modell von \citeauthor{beisbart_making_2021} bildet ein \textit{narrow} RE ab, denn bei einem \textit{wide} RE würden Hintergrundtheorien miteinbezogen werden und diesen wurde im Modell kein Platz eingeräumt. Hintergrundtheorien können während des Prozesses nicht verändert werden und geniessen einen Sonderstatus. Durch eine Einschränkung der Argumente -- diese müssen mit etwaigen Hintergrundtheorien konsistent sein -- könnte das Modell aber auch innerhalb eines \textit{wide} RE funktionieren. \parencite[vgl.][S.~459]{beisbart_making_2021}

Der Begriff \textit{Reflective Equilibrium} wurde 1971 von John Rawls geprägt. Dieser erarbeitete die Methode, um die \textit{original position} einer Gesellschaft zu rechtfertigen \parencite[vgl.][]{rawls_theory_1971}. In dieser Methode überprüft man, ob die gewählten Prinzipien mit den in Betracht gezogenen Überzeugungen (betreffend der Gerechtigkeit) übereinstimmen oder diese in akzeptierbarer Weise erweitern. Wir haben gewisse Überzeugungen (über Gerechtigkeit) für die wir klare Intuitionen haben. Diese Überzeugungen können wir als Startpunkte benutzen, um mit Prinzipien, welche diese Startpunkte erklären, weitere Überzeugungen zu erklären, für die wir keine klaren Intuitionen haben. Durch die Beschreibung der \textit{initial situation} generieren wir Prinzipien, welche wir mit den Überzeugungen abgleichen. Erklären die Prinzipien die Überzeugungen nicht, so kann man entweder die Überzeugungen anpassen oder aber die Prinzipien. Daraus entsteht -- nach möglicherweise mehrmaliger Wiederholung -- ein Reflective Equilibrium -- ein Überlegungsgleichgewicht. Er beschreibt die Überzeugungen und Theorie als jeweils eine Einheit, die auch als Einheit verändert werden. Ein Piecemeal-Ansatz -- wie in Abschnitt \ref{piecemealansatz} als Alternative vorgeschlagen -- ist bei Rawls also nicht zu finden. Rawls verweist bei der Verwendung des Begriffs \textit{Reflective Equilibrium} auf \cite{goodman_fact_1983}, welcher vor ihm über die Idee gesprochen, ihr aber noch keinen Namen gegeben hat. \parencite[vgl.][S.~20]{rawls_theory_1971}

Anders als bei Rawls, ist bei Goodman ist ein Piecemeal-Ansatz, bei dem Theorie und Überzeugungen stückweise angepasst werden, zu entdecken:

\begin{quote}
    A rule is amended if it yields an inference we are unwilling to accept; an inference is rejected if it violates a rule we are unwilling to amend. \parencite[S.~64]{goodman_fact_1983}
\end{quote}

Er spricht also von einzelnen Prinzipien (\textit{rules}), welche abgeändert werden, und nicht von einer ganzen Theorie. Und von einzelnen Überzeugungen (\textit{inference}), die angepasst werden, wenn sie einem Prinzip widersprechen, dass wir nicht ändern wollen. Nicht alle Autoren und Autorinnen, die sich zum Thema Reflective Equilibrium äussern, machen sich detaillierte Gedanken über die Anpassungsschritte. So scheint es beispielsweise bei \cite{tersman_reflective_1993} unklar, ob er sich für einen Piecemeal-Ansatz ausspricht oder nicht. Diese Unklarheit rührt wahrscheinlich daher, dass die Unterscheidung nicht im Fokus seiner Arbeit lag. Es soll aber im Fokus der vorliegenden Arbeit liegen. Dazu fasse ich zuerst kurz das Modell in \cite{beisbart_making_2021} zusammen und lege dabei das Augenmerk auf die Änderungen an einem System, da dies der Teil ist, der für den Rest der Arbeit von Interesse ist.

\section{Das konventionelle System}

Das Modell von \citeauthor{beisbart_making_2021} geht von einer Menge von Sätzen aus, die für das Thema, über welches man ein RE\footnote{Reflective Equilibrium} erhalten will, relevant sind. Diese Menge ist unter Negation geschlossen. Das heisst, wenn das Thema einen Satz enthält, so beinhaltet es auch dessen Negation. Eine doppelte Negation ist gleichbedeutend mit dem unnegierten Satz, sodass gilt: $\alpha \leftrightarrow \neg \alpha$. Es ist nicht möglich, die Menge an Sätzen $S$ im Thema während des Prozesses zu verändern. Im Verlauf der Arbeit wird oft von dialektischen Strukturen oder kurz Strukturen gesprochen. In diesen werden die inferenziellen Beziehungen zwischen den Sätzen eines Themas dargestellt. Eine dialektische Struktur enthält die Sätze des Themas und deduktiv gültige Argumente, welche zwischen den Sätzen des Themas bestehen. Worin sich die deduktive Gültigkeit begründet, wird hier bewusst offen gelassen, damit das Modell möglichst flexibel bleibt. Der Prozess, welcher abgebildet wird, beginnt mit einem initialen epistemischen Zustand. \parencite[vgl.][S.~443~f.]{beisbart_making_2021}

\paragraph{Der epistemische Zustand} Dieser epistemische Zustand besteht aus einer Theorie und einer Menge von Überzeugungen. Die Theorie wiederum besteht aus einzelnen Prinzipien. Prinzipien können beliebige Sätze aus allen Sätzen im Thema sein. Der Inhalt einer Theorie ist (dialektische) Abschluss der Prinzipien \parencite[vgl.][S.~464]{beisbart_making_2021}. So kann nun also jeder Satz in einem Satzpool Prinzip, Inhalt und/oder Überzeugung sein. Sätze folgen aus sich selbst, sodass im Inhalt einer Theorie immer auch die Prinzipien enthalten.

In Abbildung \ref{fig:smallset} ist die Menge aller Sätze folgende: $\{s1,s2,\neg s1, \neg s2\}$. Durch den Pfeil ist angedeutet, dass $s2$ aus $s1$ folgt. Dies ist das einzige Argument in der Struktur. Zum initialen Zustand gehört auch eine Menge von Überzeugungen -- in Abbildung \ref{fig:smallset} wurde zur Veranschaulichung $\{s2\}$ gewählt. Ausserdem gehört eine initiale Theorie dazu. Diese ist im Standard-Modell die leere Menge. Der Inhalt der leeren Menge ist ebenfalls die leere Menge -- das heisst, aus der leeren Menge folgen keine relevanten Sätze\footnote{Aus der leeren Menge folgen nur Tautologien, diese sind nie Teil eines Themas und daher nicht relevant}. Angenommen $\{s1\}$ wäre die Theorie, so wäre $s1$ das einzige Prinzip der Theorie und $\{s1, s2\}$ der Inhalt der Theorie.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{figure1}
  \caption{Eine kleine Menge von Sätzen\label{fig:smallset}}
\end{figure}

Hat man einen initialen epistemischen Zustand, folgt als erster Schritt die Anpassung der Theorie und -- in einem zweiten Schritt -- die Anpassung der Überzeugungen. Diese Schritte werden abwechslungsweise so oft wiederholt, bis die Stoppbedingung zutrifft. \parencite[vgl.][S.~449]{beisbart_making_2021}

Für die Änderung der Theorie werden verschiedene Theoriekandidaten miteinander verglichen. Ich werde später darauf zu sprechen kommen, wie diese gefunden werden. Die Kandidaten werden mittels einer Achievement-Funktion verglichen.

\paragraph{Die Achievement-Funktion} \label{achievement-funktion}
Die Achievement-Funktion untersucht einen epistemischen Zustand auf die Kriterien der \textit{Kohärenz (Account)}, der \textit{Systematizität (Systematicity)} und des \textit{Respekts (Faithfulness)}. \textit{Kohärenz} beschreibt, wie sehr die Theorie die Überzeugungen erklärt. Dabei die Kohärenz von drei Faktoren ab: Die Kohärenz wird für jede Überzeugung verringert, die mit der Theorie inkonsistent ist. (b) sie verringert sich für jede Überzeugung, die nicht im Inhalt der Theorie ist und schliesslich verringert sie sich (c) für jeden Satz im Inhalt der Theorie, der keine Überzeugung ist. Vor allem dieser letzte Punkt scheint etwas kontraintuitiv. Warum sollte es schlechter für die Kohärenz sein, wenn eine Theorie mehr erklärt, als die nur die akzeptierten Überzeugungen? \citeauthor{beisbart_making_2021} erklären dies damit, dass dies einen Druck dahingehend erzeugen soll, dass die Überzeugungen alle Sätze im Inhalt der Theorie bei den Anpassungsschritten der Überzeugungen aufnehmen \parencite[vgl.][S.~448]{beisbart_making_2021}.
\textit{Systematizität} bezieht sich nur auf die Theorie eines epistemischen Zustandes. Je mehr Sätze im Inhalt einer Theorie sind im Verhältnis zu den Sätzen in der Theorie, umso systematischer ist die Theorie. Eine Theorie, die nur aus einem Satz besteht, deren Inhalt aber vier Sätze umfasst, ist also systematischer, als eine Theorie, die ebenfalls aus einem Satz besteht, aber deren Inhalt nur eben diesen Satz enthält.
\textit{Respekt} bezieht sich nur auf die Überzeugungen eines epistemischen Zustandes. Der Respekt der Überzeugungen verschlechtert sich für jede initiale Überzeugung, welche negiert in den Überzeugungen vorkommt und für jede initiale Überzeugung, die nicht vorkommt.
Die genauen Formeln zur Berechnung der Achievement-Funktion finden sich in \cite[S.~464~ff.]{beisbart_making_2021}.

\paragraph{Gewichtung} Diese drei Desiderata sind unterschiedlich gewichtet. Dies ist wichtig, da die Desiderata einen epistemischen Zustand oft in unterschiedliche Richtungen ziehen. Beispielsweise wird ein epistemischer Zustand kohärenter, wenn man alle Überzeugungen entfernt, die nicht Teil des Inhalts sind. Darunter kann allerdings der Respekt leiden. Deshalb müssen die Desiderata unterschiedlich gewichtet werden, damit Ergebnisse erzielt werden können, die nicht gleich wie der initiale epistemische Zustand sind. Ich verwendete für meine Ensemblestudie lediglich die Standard-Gewichte von \citeauthor{beisbart_making_2021} (Kohärenz: 0.35, Respekt: 0.10, Systematizität: 0.55) -- Das Modell erlaubt aber auch andere Gewichtungen, was sinnvoll sein könnte, wie ich zeigen werde. \parencite[vgl.][S.~448]{beisbart_making_2021}

\paragraph{Konsistenz\label{konsistenz}}
Ich habe bisher den Begriff der Konsistenz schon einige Male verwendet, ohne genau zu definieren, was dieser bedeutet. Das möchte ich nun ändern. Konsistenz bedeutet in der Logik, dass eine Menge von Sätzen gleichzeitig wahr sein kann, dass also aus ihr kein Widerspruch abgeleitet werden kann. In dieser Arbeit spielen zwei Arten der Konsistenz eine Rolle: minimale Konsistenz und volle Konsistenz. Bei der \textit{minimalen Konsistenz} wird lediglich gefordert, dass die Menge von Sätzen nicht einen Satz des Themas und gleichzeitig dessen Negation enthält. Bei \textit{voller Konsistenz}, welche von Theorien verlangt wird, werden die inferenziellen Beziehungen von Sätzen miteinbezogen. Wenn also bspw. der Satz $s3$ aus $s1$ folgt und aus $s2$ folgt $\neg s3$, so wäre die Menge von Sätzen ${s1,s2}$ inkonsistent, denn aus ihr folgt $s3$ und $\neg s3$ und dies ist ein Widerspruch (Siehe dazu Abbildung \ref{fig:inconsistency}). Anders ausgedrückt kann man auch sagen, dass, wenn von einer Theorie volle Konsistenz gefordert wird, von Ihrem Inhalt minimale Konsistenz gefordert wird. Im Inhalt dürfen sich keine Sätze finden, deren Negationen auch darin enthalten sind.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{consistence.png}
  \caption{Möglichkeit der Inkonsistenz\label{fig:inconsistency}}
\end{figure}

Wenn Überzeugungen im Modell von \citeauthor{beisbart_making_2021} angepasst werden müssen, so funktioniert dies nach einem einfach beschriebenen Ablauf:

\begin{quote}
    [...] the agent replaces her current commitments $C_i$ with those commitments $C_{i+1}$ that score best on the achievement function Z (given $T_{i+1}$).
    \parencite[S.~450]{beisbart_making_2021}
\end{quote}

Die Menge von Überzeugungen, welche (zusammen mit der aktuellen Theorie) den höchsten Wert der \textit{Achievement-Funktion} $Z$ erreicht, wird als neue Menge von Überzeugungen übernommen. Aber welche Mengen von Überzeugungen ($C^*$) stehen uns überhaupt zur Verfügung? Die Anzahl der Mengen von Überzeugungen in $C^*$ ($\lvert C^* \lvert$) ist von der Menge an Sätzen im Thema bestimmt. Je mehr Sätze, umso mehr Mengen von Überzeugungen. Das Problem ist, dass $\lvert C^* \lvert$ exponentiell zur Zahl der Sätze im Thema wächst. Pro zwei hinzugefügte Sätze (ein Satz und dessen Negation) in einem Thema verdreifacht sich die Anzahl der Mengen von Überzeugungen. Das kommt daher, dass ein Satz oder seine Negation Teil einer Menge von Überzeugungen sein kann oder er ist nicht dabei. Das sind pro nicht-negiertem Satz drei Möglichkeiten. Aus diesen Überlegungen leitet sich die Zahl der zu überprüfenden Mengen von Überzeugungen pro Anpassungsschritt ab: $\lvert C^* \rvert = 3^n$, wobei $n$ die Zahl der nicht negierten Sätze im Thema ist. Es gilt zu beachten, dass noch mehr als drei Möglichkeiten pro neuen Satz bestehen: Es könnte ja auch der Satz und seine Negation Teil einer Menge von Überzeugungen sein. Diese Möglichkeit wird aber ausgeschlossen, da von Mengen von Überzeugungen \textit{minimale Konsistenz} gefordert wird.

Die Regel zur Anpassung einer Theorie sieht zwar analog aus, allerdings können die Sätze, welche überprüft werden müssen, etwas eingeschränkt werden.

\begin{quote}
    [...] the agent newly adopts an epistemic state $(C_i, T_{i+1})$ such that the theory $T_{i+1}$ scores best in terms of the achievement function $Z$ given $C_i$.
    \parencite[S.~450]{beisbart_making_2021}
\end{quote}

Zusätzlich schränken nun die Inferenzbeziehungen zwischen den Sätzen die Kandidaten für die neue Theorie ein. Weil Theorien vollständig konsistent sein müssen, darf auch kein Theoriekandidat Inkonsistenzen enthalten.
Im traditionellen Ansatz werden inkonsistente Mengen vorneweg ausgeschlossen, um später nicht immer wieder einzeln die Konsistenz prüfen zu müssen. Deshalb wird zu Beginn der Inhalt jeder möglichen Theorie ($3^n$) errechnet und abgespeichert. Alle Mengen mit Inhalten, die Widersprüche enthalten, werden ausgeschlossen. Dies bedeutet aber auch einen Mehraufwand, weil über alle möglichen Theorien iteriert werden muss.

Für eine sehr kleine Menge von Sätzen gelingt eine übersichtliche Darstellung der Theoriekandidaten noch. Bei Abbildung \ref{fig:smallset} ist eine sehr kleine Menge von Sätzen abgebildet. Wenn nun \textit{s2} die einzige Überzeugung ist und man dazu die passende Theorie suchen möchte, so würden folgende Kombinationen überprüft: $\{\{\}, s1, s2, \neg s1, \neg s2, \{s1,s2\}, \{s1,\neg s2\}, \{\neg s1, s2 \}, \{\neg s1, \neg s2 \} \}$. In dieser einfachen Struktur können keine Mengen ausgeschlossen werden. Alle 9 Elemente müssten überprüft werden. Wenn nun ein einziges weiteres Element \textit{s3} hinzukäme, müssten 27 Mengen überprüft werden. Bei einem weiteren 81. Das heisst, der Arbeitsaufwand wächst exponentiell zur Anzahl Sätzen im System. Dies macht diese Methode unrealistisch in der Benutzung. Ausserdem ist es auffällig, wie schnell und einfach die Anpassung intuitiv gemacht werden kann. Für eine Person ist es auf einen Blick zu erkennen, dass s1 das einzige Prinzip ist, welches infrage kommt. Deshalb muss ein neuer Ansatz entwickelt werden. Eine Alternative bietet der Piecemeal-Ansatz.


\section{Der Piecemeal-Ansatz} \label{piecemealansatz}
Wie \cite[S.~461]{beisbart_making_2021} feststellten, scheint die naheliegendste und einfachste Umsetzung eines Piecemeal-Ansatzes zu sein, einzelne Überzeugungen oder Prinzipien in einer vorhandenen Theorie bzw. Menge von Überzeugungen zu ändern bzw. einzelne neue Sätze hinzuzufügen. So geht es im Piecemeal-Ansatz denn auch um die Idee, von den bestehenden Überzeugungen bzw. der bestehenden Theorie auszugehen anstatt agnostisch davon auszugehen, dass sich alle möglichen Theorien gleich gut für die Anpassung eignen. Man ändert die bestehende Theorie bzw. die bestehenden Überzeugungen um ein einzelnes Element ab und sieht, ob diese abgeänderte Theorie bzw. die abgeänderten Überzeugungen besser zu ihrem Gegenstück passen. Im Folgenden werde ich den Prozess, der zum Erreichen eines Überlegungsgleichgewichts führt und seine Einzelteile detailliert erklären.

\subsection{Der Anpassungsprozess}
Der Ablauf des Prozesses -- wie aus einer dialektischen Struktur von Sätzen und einer Menge von Anfangsüberzeugungen ein Überlegungsgleichgewicht entsteht -- ist im Grunde genommen nicht anders als der des traditionellen Ansatzes, nur die einzelnen Schritte sind anders definiert. In einem ersten Schritt wird der initiale epistemische Zustand definiert, der aus der ersten Theorie ($T_0$) und den initialen Überzeugungen ($C_0$) besteht. $T_0$ ist als die leere Menge (\{\}) festgesetzt.\footnote{Einen Vorschlag für eine alternative initiale Theorie befindet sich \hyperref[better-first-theory]{im Anhang}.} $C_0$ ist als Eingabe neben der dialektischen Struktur der Sätze gegeben. Danach wird die bestehende Theorie an die aktuellen Überzeugungen angepasst. Dabei wird die Theorie, welche die höchsten Werte der Desiderata Kohärenz und Systematizität erreicht, zur neuen Theorie gewählt, wenn die Werte besser sind als die der bestehenden Theorie. Im nächsten Schritt wird die Menge der Überzeugungen an die geänderte Theorie angepasst. Dabei wird diejenige Menge der Überzeugungen gewählt, welche die höchsten Werte der Desiderata Kohärenz und Respekt erreicht, sofern die Werte höher sind als bei der bisherigen Menge von Überzeugungen. Die ersten drei Schritte des jeweiligen Anpassungsprozesses sind durch die drei möglichen Operationen, die man auf eine Menge, in der nur ein Satz verändert werden soll, anwenden kann, hergeleitet. Man kann einen Satz hinzufügen, einen Satz negieren oder einen Satz entfernen. Die beiden Anpassungsschritte werden so lange nacheinander angewendet, bis die Änderungen keine Verbesserung des Wertes der Achievement-Funktion mehr bringt. 

\subsubsection{Anpassung der Theorie} \label{T-Anpassung}
Ausgehend von einer Menge von Überzeugungen $C_i$ wird eine Theorie $T_i$ wie folgt angepasst: 
\begin{enumerate}
    \item \label{1} Alle Sätze $s$ des Themas $S$ (auch die Negationen) werden einzeln zu der Menge von Prinzipien in $T_i$ hinzugefügt, falls sie oder ihre Negationen noch nicht enthalten sind. Die Menge der daraus entstandenen Theoriekandidaten heisst $T_i^*$. Die Sätze in $S$ sind indexiert.
    $$ 
        T_i^*:= \{ T_i \cup \{s_j\}: (s_j \in S \setminus T_i) \land (\neg s_j \not\in T_i) \}
    $$
    \item \label{1.1} Jede Menge, die entsteht, wenn man einen einzelnen Satz in $T_i$ negiert wird zu $T_i^*$ hinzugefügt. Die daraus entstandene Menge heisst $T_i^{**}$.
    $$
        T_i^{**}:= T_i^* \cup \{ (T_i \setminus \{s_j\}) \cup \{\neg s_j\}: s_j \in T_i\}
    $$
    \item \label{2} Die Mengen, die entstehen, wenn man einzelne Prinzipien aus $T_i$ entfernt, und $T_i^{**}$ werden vereinigt. Die daraus entstandene Menge heisst $T_i^{***}$.
    
    $$
        T_i^{***}:= T_i^{**} \cup \{ T_i \setminus \{s_j\}: s_j \in T_i\}
    $$
    
    \item \label{konsistenzfilter} Inkonsistente\footnote{Von den Mengen wird vollständige Konsistenz gefordert. Weiteres dazu in Abschnitt \ref{konsistenz}.} Mengen werden aus $T_i^{***}$ entfernt. Die daraus entstandene Menge heisst $T_i^{****}$.
    
    $$
        T_i^{****}:= T_i^{***} \setminus \{f : f \in T_i^{***} \land f \text{ ist inkonsistent} \}
    $$
    \item \label{3} Für jedes Element der Menge $T_i^{****}$ wird der Wert der Achievement-Funktion $Z$ ermittelt.
    \item \label{4} Der Theoriekandidat, welcher den höchsten Wert bei $Z$ erreicht, wird zur Theorie $T_{i+1}$ erklärt, falls sein $Z$-Wert auch strikt grösser ist als jener von $T_i$ -- Ansonsten wird $T_i$ zu $T_{i+1}$. Falls mehrere Mengen den gleichen, höheren Wert als $T_i$ erreichen, wird zufällig eine der Mengen ausgewählt.\footnote{Dies ist möglicherweise nicht die beste Option. Eventuell wäre es ratsamer, an dieser Stelle den RE-Prozess für alle Mengen mit den gleichen $Z$-Werten durchzuführen und somit den Prozess an dieser Stelle zu verzweigen. Das vorgestellte Modell könnte in dieser Weise angepasst werden. Diese Option gilt es noch zu prüfen und könnte Gegenstand zukünftiger Arbeiten sein}
\end{enumerate}

\subsubsection{Anpassung der Überzeugungen} \label{C-Anpassung}
Analog verläuft auch die Überzeugungsanpassung an die Theorie $T_i$. Einzig Schritt \ref{konsistenzfilter} kann ausgelassen werden, da die Menge von Überzeugungen nur minimal konsistent sein muss.
\begin{enumerate}
    \item \label{c1} Alle Sätze des Themas $S$ werden einzeln zu der Menge von Überzeugungen in $C_i$ hinzugefügt, falls sie oder ihre Negationen noch nicht enthalten sind. Die Menge der daraus entstandenen Mengen von Überzeugungen heisst $C_i^*$. Die Sätze in $S$ sind indexiert.
    
    $$ 
    C_i^*:= \{ C_i \cup \{s_j\}: (s_j \in S \setminus C_i) \land (\neg s_j \not\in C_i) \}
    $$
    
    \item \label{c1.1} Jede Menge von Sätzen, die entsteht, wenn man einen einzelnen Satz in $C_i$ negiert, wird zu $C_i^*$ hinzugefügt. Die daraus entstandene Menge heisst $C_i^{**}$.
    
    $$
    C_i^{**}:= C_i^* \cup \{ (C_i \setminus \{c_j\}) \cup \neg c_j: c_j \in C_i\}
    $$
    
    \item \label{c2} Die Mengen, die entstehen, wenn man einzelne Überzeugungen aus $C_i$ entfernt, werden mit $C_i^{**}$ vereinigt.
    
    $$
    C_i^{***}:= C_i^{**} \cup \{ C_i \setminus \{c_j\}: c_j \in C_i\}
    $$
    
    \item \label{c3} Für jedes Element der Menge $C_i^{***}$ wird der Wert der Achievement-Funktion $Z$ ermittelt.
    \item \label{c4}Die Menge von Überzeugungen, welche den höchsten Wert bei $Z$ erreicht, wird zu $C_{i+1}$ erklärt, falls ihr $Z$-Wert auch strikt grösser ist als jener von $C_i$ -- Ansonsten wird $C_i$ zu $C_{i+1}$. Falls mehrere Mengen den gleichen, höheren Wert als $C_i$ erreichen, wird zufällig eine der Mengen ausgewählt.\footnotemark[\value{footnote}]
\end{enumerate}

\subsubsection{Stoppbedingung}
Die beiden Schritte \hyperref[T-Anpassung]{Theorieanpassung} und \hyperref[C-Anpassung]{Überzeugungsanpassung} werden nacheinander abwechselnd wiederholt, bis beide Schritte keine Änderung der Position mehr bringen, bis also $(C_i, T_i) = (C_{i+1}, T_{i+1})$. Wenn also bei Schritt \ref{c4} der Überzeugungsanpassung und Schritt \ref{4} der Theorieanpassung jeweils die bestehende Menge zur neuen Menge wird, weil deren $Z$-Wert höher oder gleich hoch ist, wie jener der Menge mit dem höchsten Wert im aktuellen Schritt, stoppt der Prozess des Angleichens. Dadurch wird garantiert, dass der Prozess aufhört, das heisst, dass ein Fixpunkt erreicht wird. Die Stoppbedingung ist dieselbe, wie \cite[S.~450]{beisbart_making_2021} sie schon definiert haben.

\subsection{Aufwand}
Allgemein lässt sich sagen, dass in Schritt 1 der beiden Anpassungen immer $\lvert S \rvert - 2\lvert C_i \text{ bzw. } T_i \rvert$ Kandidaten hinzukommen. Da $\lvert C_i \text{ bzw. } T_i \rvert$ nie grösser als $\lvert S \rvert/2$ werden kann, kann diese Formel nicht kleiner als 0 werden. Wenn $C_i/T_i$ einen Satz enthält, kann dieser und seine Negation nicht mehr hinzugefügt werden. In den Schritten 2 \& 3 kommen hingegen jeweils $\lvert C_i \rvert / \lvert T_i \rvert$ Kandidaten hinzu. Das führt dazu, dass in jedem Anpassungsschritt insgesamt $\lvert S \rvert$ Kandidaten hinzugefügt werden. Bei den Theorieanpassungen, werden allerdings nicht konsistente Mengen wieder entfernt. Somit wächst der Aufwand für die Überprüfung der Mengen pro Schritt linear zur Mächtigkeit von $S$. Im Vergleich zum exponentiellen Wachstum im traditionellen Ansatz ist dies ein klarer Fortschritt. Es stellt sich nur die Frage, ob die Anzahl an Schritten im Piecemeal-Ansatz nicht exponentiell wächst. Dies werde ich in Abschnitt \ref{Ensemblestudie} experimentell annähern.

\subsection{Beispiel}
\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/reduced_classical.png}
  \caption{Beispielstruktur\label{fig:classset-initial1}}
\end{figure}

 Als Beispiel für den Ablauf eines Piecemeal-Prozesses kann die folgende Struktur genommen werden:
 \begin{enumerate}
     \item Die Struktur beinhaltet 5 Sätze: $\{s1,...,s5\}$
     \item Aus $s1$ folgen $s3, s4, s5$.
     \item Aus $s2$ folgen $\neg s4, s5$
 \end{enumerate}
 
 Die initialen Überzeugungen ($C_0$) definiere ich wie folgt:
 
 $C_0 = \{s3, s4, s5\}$
 
 Diese Struktur und die initialen Überzeugungen sind auf Abbildung \ref{fig:classset-initial1} verbildlicht.\footnote{Die Zeichen unter den Satzbezeichnungen sind wie folgt zu deuten: \textit{Position in der Theorie | Position in den Überzeugungen} Dabei steht X für: \textit{Dieser Satz kommt in der Menge nicht vor}. T für \textit{Dieser Satz ist in der Menge} und F für \textit{Die Negation des Satzes ist in der Menge.} Zusätzliche Klammern (()) können vorkommen, um anzuzeigen, dass diese Position notwendig ist, um kohärent zu sein.}
 Der initiale epistemischer Zustand $(C_0, T_0)$ ist gegeben durch die leere Menge und die oben definierten initialen Überzeugungen. Zur ersten Anpassung der Theorie -- also um $T_1$ zu finden -- wird nun die initiale Theorie genommen und ihr werden einzeln alle Sätze des Themas $S$ hinzugefügt.
 $$
 T_0: \{\} \longrightarrow T_0^*: \{\{s1\},...,\{s5\}, \{\neg s1\}, ..., \{\neg s5\}\}
 $$
 Beim \hyperref[1.1]{zweiten Schritt} kommt keine Menge hinzu, denn in der leeren Menge gibt es keine Sätze, die negiert werden könnten. Auch beim \hyperref[2]{dritten Schritt} kommen keine neuen Sätze hinzu, denn man kann keine Sätze aus der leeren Menge entfernen. Im \hyperref[konsistenzfilter]{vierten Schritt} können keine Mengen entfernt werden, denn eine Menge mit einem Element kann nie inkonsistent sein. Die erste Anpassung der Theorie überprüft also einfach alle einzelnen Sätze $\{s1,...,s5, \neg s1, ..., \neg s5\}$. Derjenige, welcher den höchsten Wert von $Z$ erreicht, wird zum einzigen Prinzip. Dies ist $s1$, dessen Inhalt $\{s1,s3,s4,s5,\neg s2\}$ ist. Er erhält die meisten Punkte im Desiderat Kohärenz, denn sie enthält alle Überzeugungen im Inhalt und keine der Überzeugungen ist inkonsistent mit der Theorie. Abzüge erhält $\{s1\}$ nur im Bereich Kohärenz, weil sie viele Sätze impliziert, die gar nicht Teil der Überzeugungen sind: $\{s1, \neg s2\}$ sind im Inhalt, aber nicht in den Überzeugungen. Trotzdem erreicht $\{s1\}$ den höchsten Wert bei $Z$ und wird damit zu $T_1$.
 
 Die Überzeugungen müssen als Nächstes angepasst werden. Dazu überprüfen wir die Menge von Mengen, welche $C_0$ und einen weiteren Satz enthalten.
 
 \begin{equation} \notag
 \begin{split}
 C_0^*: \{\{s3, s4, s5, \textcolor{red}{s1}\}, \{s3, s4, s5, \textcolor{red}{s2}\}, \\
 \{s3, s4, s5, \textcolor{red}{\neg s1}\}, \{s3, s4, s5, \textcolor{red}{\neg s2}\}\}
 \end{split}
 \end{equation}
 
 In Schritt \ref{c1.1} werden dann alle Mengen erstellt, die entstehen, wenn man einzelne Sätze in $C_0$ negiert.
 
 \begin{equation} \notag
 \begin{split}
 C_0^{**}: C_0^* \cup \{\{\textcolor{red}{\neg s3}, s4, s5\}, \{s3, \textcolor{red}{\neg s4}, s5\}, \{s3, s4, \textcolor{red}{\neg s5}\}\}
 \end{split}
 \end{equation}
 
 Ausserdem überprüfen wir gemäss Schritt \ref{c2} die Mengen, welche entstehen, wenn man einen einzelnen Satz aus $C_0$ entfernt.
 
$$
    C_0^{***}: C_0^{**} \cup \{ \{s4,s5\}, \{s3,s5\}, \{s3,s4\} \}
$$
 
 Von all den Überzeugungsmengen in $C_0^{***}$ erreichen folgende zwei Mengen den gleichen Wert der Achievement-Funktion: $\{s3,s4,s5,s1\}$, $\{s3,s4,s5,\neg s2\}$. Ob man also $s1$ oder $\neg s2$ zu den weiteren Überzeugungen hinzunimmt, spielt für die nächste Generation keine Rolle. Bei beiden Optionen wird das Desideratum der Kohärenz etwas besser erfüllt und das Desideratum des Respekts etwas weniger gut als beim vorherigen Zustand, denn es befindet sich ein Satz in der Überzeugungsmenge, der nicht zur ursprünglichen Überzeugungsmenge gehört. 
Eine der beiden Möglichkeiten wird nun zufällig ausgewählt. Wir legen uns für das Beispiel fest: $C_1 = \{s3, s4, s5, \neg s2\}$
 
 Bei der zweiten Anpassung der Theorie müssen nun folgende Theoriekandidaten geprüft werden:
\begin{align}
    T_1^{*}: &\{\{s1, s3\}, \{s1, s4\}, \{s1, s5\},\stkout{\{s1, s2\}}, \{s1, \neg s2\}, \stkout{\{s1, \neg s3\}, \{s1, \neg s4\}, \{s1, \neg s5\}}\}\\
    T_1^{**}: T_1^{*} \cup &\{\{\neg s1\}\}\\
    T_1^{***}: T_1^{**} \cup &\{\{\}\}\\
    T_1^{****}: T_1^{***} \setminus &\{f : f \in T_1^{***} \land f \text{ ist inkonsistent} \} = \{\{s1, s3\}, \{s1, s4\}, \{s1, s5\}, \{s1, \neg s2\}, \{\neg s1\}\} \notag
\end{align}
Die durchgestrichenen Kandidaten werden in Schritt \ref{konsistenzfilter} entfernt, weil sie inkonsistent mit $\{s1\}$ sind.
 Das Resultat ist, dass keine der überprüften Theorien besser ist als $T_1$. Somit wird $T_1$ auch zu $T_2$ übernommen.
 
 Es folgt eine weitere Anpassung der Überzeugungen. Wir erinnern uns, dass wir im letzten Anpassungsschritt die Wahl zwischen der Hinzufügung von $s1$ oder $\neg s2$ zu $C_0$ hatten. Wir hatten uns zufällig für die zweite Option entschieden. Da sich die Theorie im letzten Anpassungsschritt nicht verändert hat und die beiden Optionen -- von denen eine zufällig ausgewählt wurde -- nicht inkonsistent waren, ist es der Fall, dass das Hinzufügen von $s1$ zu $C_1$ die beste Alternative ist. Ich überspringe an dieser Stelle also das Aufzeichnen und Vergleichen von $C_1^{***}$ und füge $s1$ zu $C_1$ hinzu. Somit sieht $C_2$ nun wie folgt aus: $C_2 = \{s3, s4, s5, \neg s2, s1\}$
 
 Weil $T_2$ mit $T_1$ identisch ist, müssen im nächsten Theorieanpassungsschritt, um $T_3$ zu finden, auch dieselben Theoriekandidaten überprüft werden. Da die Hinzufügung von $s1$ zu den Überzeugungen optimal -- das heisst sie hat den Wert der Achievement-Funktion maximiert -- für $T_2$ war, kann es keine Theorie geben, die besser passt. Denn wäre das der Fall, so müssten wir in einem der vorherigen Theorieanpassungsschritten eine suboptimale Theorie ausgewählt haben. Das führt mich zur Annahme, dass bei einer dialektischen Struktur mit Argumenten, die nur eine Prämisse haben, keine weiteren Theorieanpassungsschritte unternommen werden müssen, wenn in einem Schritt keine bessere Theorie gefunden wurde. Diese Vermutung soll an dieser Stelle so stehen gelassen werden, da ihr Beweis den Rahmen dieser Arbeit sprengen würde und ihre Wahrheit an dieser Stelle nicht relevant ist. Für das Beispiel lässt sich aber feststellen, dass es keine bessere Theorie als $\{s1\}$ gibt. $T_3$ ist daher $\{s1\}$.
 
 Es folgt eine letzte Überprüfung der Überzeugungen. Folgende Mengen werden überprüft:
 \begin{align}
    C_2^{*}: &\{\}\\
    C_2^{**}: C_2^{*} \cup &\{\{\neg s3, s4, s5, \neg s2, s1\}, \{s3, \neg s4, s5, \neg s2, s1\}, \{s3, s4, \neg s5, \neg s2, s1\},\\ \notag
    &\{s3, s4, s5, s2, s1\}, \{s3, s4, s5, \neg s2, \neg s1\}\}\\
    C_2^{***}: C_2^{**} \cup &\{\{s3, s4, s5, \neg s2\}, \{s3, s4, s5, s1\}, \{s3, s4, \neg s2, s1\}, \{s3, s5, \neg s2, s1\},\\ \notag
    &\{s4, s5, \neg s2, s1\}\}
 \end{align}
 
 Dabei fällt auf, dass mit $C_2^{*}$ keine neuen Kandidaten gefunden werden können. Denn jeder Satz in S kommt schon in $C_2$ vor oder seine Negation kommt darin vor. Dafür werden in den folgenden Schritten jeweils $\lvert S \rvert = 5$ Mengen gefunden, welche überprüft werden müssen.
 Nach dem beschriebenen Ablauf wird der Anpassungsschritt wieder durchgeführt, mit dem Ergebnis, dass es keine Verbesserung gibt und $C_3$ mit $C_2$ gleichgesetzt wird. Weil bei der letzten Theorieanpassung schon keine bessere Theorie gefunden wurde, ist damit die Stoppbedingung erfüllt und der Prozess endet in einem Reflective Equilibrium.
 
 Während des Prozesses mussten in den drei Theorieanpassungsschritten 22 Theoriekandidaten (30 Kandidaten -- 8 inkonsistente Mengen) überprüft werden. Beim traditionellen Ansatz hingegen müssen in jedem Schritt $3^5$ Mengen (abzüglich der inkonsistenten Theoriekandidaten) überprüft und verglichen werden. In der Anpassung der Überzeugungen im Beispiel müssen bei allen drei Anpassungen insgesamt 30 Überzeugungen überprüft werden. Beim traditionellen Ansatz müssen bei jedem Schritt wieder $3^5$ Überzeugungen überprüft werden. Wichtig für die Frage, ob der traditionelle Ansatz wirklich weniger effizient ist, ist neben der Anzahl zu überprüfender Mengen pro Schritt auch die Anzahl der Schritte. Diese wäre für unser Beispiel für das traditionelle Modell bei beiden Anpassungen 3 Schritte, für den neuen Ansatz sind es auch je 3 Schritte. Die Anzahl Schritte ist also gleich hoch, aber die Anzahl von hinzugefügten Mengen pro Schritt ist $48,6$ mal tiefer im Piecemeal-Ansatz. Wenn sich bei weiteren Kompositionen ähnliche Werte ergeben, ist die neue Methode der traditionellen vorzuziehen. Zudem gilt es zu überprüfen, ob die Methode globale Optima erreicht. Ausserdem gibt es für Piecemeal einige weitere Einschränkungen und Schwierigkeiten, auf die ich in Abschnitt \ref{mehrAlsEineP} noch zu sprechen komme.

\section{Ensemblestudie} \label{Ensemblestudie}

Um zu untersuchen, wie sich der Piecemeal-Ansatz gegenüber dem Standard-Ansatz verhält, habe ich ein umfangreiches Datenset generiert und dieses analysiert. Ich werde in diesem Abschnitt kurz darauf eingehen, wie das Datenset aufgebaut ist, und dann erklären, was ich untersucht habe und was die Erkenntnisse sind. Generiert wurden die Daten mittels einer Python-Bibliothek, wie von den Mitgliedern des Forschungsprojekts \href{https://www.philosophie.unibe.ch/forschung/forschungsprojekte/how_far_does_reflective_equilibrium_take_us/project/index_ger.html}{\textit{How Far Does Reflective Equilibrium Take Us?}} erarbeitet wurde. Alle Grafiken in diesem Teil können als interaktive SVGs auf dieser Website abgerufen werden: \href{https://piecemeal.flicks.jetzt/}{piecemeal.flicks.jetzt}. Die Grafiken sind dort besser lesbar und die exakten Werte werden an der Position der Maus angezeigt.

\paragraph{Aufbau} Es wurden 2400 RE-Prozesse generiert. Die Hälfte der Prozesse durchliefen einen Piecemeal-Ansatz und die andere Hälfte den Standard-Ansatz. Angefangen bei einer Menge von fünf Sätzen in der Gesamtsatzmenge wurden jeweils 50 zufällige Argumentstrukturen mit Argumenten, die eine Prämisse enthalten, generiert und mit 2 zufällig generierten Mengen von initialen Überzeugungen kombiniert. Dann wurden noch einmal 50 Strukturen mit zwei zufällig generierten Mengen von Überzeugungen kombiniert, aber diesmal wurden auch Argumente mit bis zu zwei Prämissen erlaubt. Dies wurde für Gesamtsatzmengen von 5 bis 10 Sätzen wiederholt, was 1200 initiale Strukturen ergibt. Alle wurden mit dem Standard-Prozess und mit dem Piecemeal-Vorschlag untersucht, was insgesamt 2400 RE-Prozesse ergibt.

\paragraph{Anzahl der initialen Überzeugungen} Es fällt auf, dass drei Viertel der Prozesse, welche dieselben initialen Strukturen haben, unterschiedliche Fixpunkte erreichen. Wenn man davon ausgeht, dass der Standard-Ansatz eigentlich immer ein globales Optimum erreicht, würde das bedeuten, dass der Piecemeal-Ansatz in diesen Fällen bei einem Fixpunkt stehen bleibt, der einen schlechteren Wert bei der Funktion Z erreicht. Dass dies nicht unbedingt so ist, lässt sich anhand von Grafiken zeigen. Je nachdem, wie viele initiale Überzeugungen in der initialen Struktur vorhanden waren, kann der Piecemeal-Ansatz durchaus bessere Ergebnisse erreichen. Bei nur einem oder zwei initialen Überzeugungen funktioniert der Standard-Ansatz immer besser. Je höher die Zahl der Überzeugungen am Anfang des Prozesses aber wird, umso besser funktioniert auch der Piecemeal-Ansatz.

\paragraph{Übersicht} Um eine grobe Übersicht über das Ensemble zu erhalten, möchte ich die wichtigsten Kennzahlen betrachten. 52,92~\% aller Prozesse haben ein globales Optimum erreicht. Dies ist viel weniger als erwartet. Ein Grund dafür könnte sein, dass der Piecemeal-Ansatz viel schlechter funktioniert als der Standard-Ansatz und so den Durchschnitt herunterzieht. Dies ist aber nicht der Fall, wie sich erkennen lässt, wenn man die beiden Ansätze einzeln auswertet: 54,17~\% der Standard-Prozesse und 51,67~\% der Piecemeal-Prozesse haben ein globales Optimum erreicht. Wenn man vergleicht, wie oft welcher Prozess besser war, so ergibt sich ein interessantes Bild: Der Standard-Prozess hat insgesamt in 376 (31,33~\%) Fällen einen höheren Wert bei der Achievement-Funktion erreicht, als der entsprechende Piecemeal-Prozess mit derselben dialektischen Struktur und denselben initialen Überzeugungen. In 302 ($25.1\overline{6}~\%$) Fällen hat der Piecemeal-Prozess einen höheren $Z$-Wert erreicht. In den verbleibenden 522 ($43,5~\%$) Fällen waren beide Ansätze gleich gut. Dies hat mich zunächst sehr überrascht, denn die Werte der Achievement-Funktion sind Gleitkomma-Werte oft mit mehr als 5 Stellen nach dem Komma. Auf den ersten Blick scheint es also sehr unwahrscheinlich, dass in 522 Fällen, von denen 75 \% unterschiedliche Fixpunkte haben, der exakt gleiche $Z$-Wert erreicht wird. Tatsächlich wurden im vorliegenden Ensemble nur 121 verschiedene Werte der Achievement-Funktion erreicht, wobei auf die häufigsten 12 Werte mehr als die Hälfte aller Überlegungsgleichgewichtsprozesse fallen. Damit ist es dann auch nicht weiter verwunderlich, dass in fast der Hälfte der Fälle, der gleiche Wert der Achievement-Funktion getroffen wurde.


\subsection{Entdeckte Probleme} \label{found problems}
\paragraph{Falsche Reihenfolge der Anpassungen} Der von der Forschungsgruppe programmierte Ansatz funktioniert nicht genau wie der Prozess, den ich in Absatz \ref{piecemealansatz} definiert habe. Der wichtigste Unterschied ist folgender: Die Reihenfolge, in der die Schritte unternommen werden, ist vertauscht. Sie sieht wie folgt aus:
\begin{enumerate}
    \item $C_0$ wird definiert aus den eingegebenen Überzeugungen.
    \item $T_0$ wird als leere Menge definiert.
    \item Die Überzeugungen passen sich an die aktuelle Theorie an.
    \item Die Theorie passt sich an die aktuellen Überzeugungen an.
    \item Die beiden vorherigen Schritte werden wiederholt, bis die Stoppbedingung eintrifft.
\end{enumerate}

Diese Reihenfolge führt dazu, dass in einem ersten Schritt immer die Menge der Überzeugungen an die leere Menge angepasst wird, was in jedem Fall dazu führt, dass ein zufälliger Satz aus der Menge der Überzeugungen gestrichen wird. Dies kann natürlich nur hinderlich sein. Im besten Fall führt es zu einigen zusätzlichen Anpassungsschritten, im schlechtesten Fall zu einem intuitiv nicht nachvollziehbaren Ergebnis.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/wierd.png}
  \caption{Struktur, die zu einem nicht nachvollziehbaren Ergebnis führt.\label{fig:wierd}}
\end{figure}

Um ein Beispiel einer solchen nicht nachvollziehbaren Struktur zu untersuchen, betrachten wir die Struktur, die in Abbildung \ref{fig:wierd} abgebildet ist. Wenn die Menge der Überzeugungen nur ein Element enthält -- wie in unserem Fall $s4$ -- bedeutet das, dass sich nach dem ersten Anpassungsschritt an die initiale Theorie -- welche die leere Menge ist -- die leere Menge auch als Überzeugungsmenge ergibt. An die leere Menge der Überzeugungen passt sich dann die leere Menge der Theorie an und wählt einen zufälligen Satz, aus dem keine anderen Sätze folgen, aus. Warum wird nicht die leere Menge beibehalten? Sie erreicht ja volle Kohärenz, denn der Inhalt enthält alle und nur die Sätze in der Überzeugungsmenge -- keine. Weil die Systematizität der leeren Menge immer 0 ist und somit irgendein Satz besser ist als die leere Menge. Warum sollen aus dem Satz keine anderen Sätze folgen? Weil, wie in Absatz \ref{achievement-funktion} erklärt, es bei der Kohärenz Abzüge gibt, für jeden Satz im Inhalt der Theorie gibt, der nicht auch in den Überzeugungen enthalten ist. Sätze, aus denen keine anderen Sätze folgen,  enthalten im Inhalt lediglich sich selbst.
Die Überzeugungen passen sich danach wieder an den zufällig gewählten Satz an und übernehmen diesen. Das heisst, dass am Ende des Prozesses mit der gleichen Wahrscheinlichkeit entweder $s3$, $s4$ oder $s5$ als alleiniger Satz in der Theorie und Überzeugung dasteht. Dies ist enorm kontraintuitiv.

Wie kann das Problem gelöst werden? Die eine offensichtliche Antwort lautet, dass das Programm die Reihenfolge einhält, welche ich in meinem Ansatz und auch \cite[S.~466]{beisbart_making_2021} so definiert haben. Es erscheint mir auch wichtig eine bessere erste Theorie, als die leere Menge zu finden. Ein Ansatz dafür befindet sich im Anhang. Eine andere Möglichkeit wäre es, $T_0 := C_0$ zu setzen.

\paragraph{Strukturen mit mehr als einer Prämisse} \label{mehrAlsEineP}
Obwohl in dieser Arbeit nur Grafiken eingearbeitet sind, in der dialektische Strukturen abgebildet sind, die Argumente mit nur einer Prämisse haben, ist das Modell von \citeauthor{beisbart_making_2021} nicht darauf beschränkt. Es ist möglich, Argumente mit vielen Prämissen einzubauen. Beispielsweise folgt aus Satz $s1$ und $s2$ zusammen $s3$, aus $s1$ oder $s2$ allein hingegen folgt $s3$ nicht. Das folgende Argument stellt eine solche Struktur dar:

\begin{center}
\begin{tabular}{c p{9cm}}
s1 & Alle Menschen sind sterblich.\\
s2 & Sokrates ist ein Mensch.\\\hline
C(s3) & Sokrates ist sterblich. 
\end{tabular}
\end{center}

Nun ist es zwar der Fall, dass jedes Argument mit zwei oder mehr Prämissen zu einem Argument mit einer Prämisse zusammengefasst werden kann, indem man einen neuen Satz (bspw. $s4$) aus einer Konjunktion der Prämissen bildet:

\begin{center}
\begin{tabular}{c p{9cm}}
s4 & Alle Menschen sind sterblich \textit{und} Sokrates ist ein Mensch.\\\hline
C(s3) & Sokrates ist sterblich. 
\end{tabular}
\end{center}

Aber dabei geht viel verloren; wir können uns nicht mehr auf die einzelnen Sätze in $s4$ beziehen und diese beispielsweise auch nicht angreifen. Argumente werden undurchsichtiger und unklarer, wenn sie auf diese Weise zusammengefasst werden.
Jedoch lassen die bisher durchgeführten Experimente vermuten, dass der Piecemeal-Ansatz, wie er in dieser Arbeit definiert ist, mit einprämissigen Argumenten schlechter funktioniert als der Standard-Ansatz. Zur Illustration ein neues Beispiel:

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/2prem.png}
  \caption{Einfachste Struktur mit zwei Prämissen\label{fig:2prem}}
\end{figure}

Wenn wir eine Theorie für den Satz $s3$ suchen, so können wir nur einen Satz zur initialen Theorie hinzufügen. Aber egal, ob wir $s1$ oder $s2$ hinzufügen, es wird weder die Kohärenz noch die Systematizität verbessert! Dies liegt daran, dass $s1$ alleine hat nur $s1$ zum Inhalt hat. Gleiches gilt für $s2$. Zum Zustand, dass $\{s1,s2\}$ die Theorie bildet, kommen wir nur über zwei Schritte, wobei der erste Schritt nie optimal ist. Dies führt dazu, dass bei dialektischen Strukturen mit Argumenten, die zwei Prämissen enthalten, kein globales Optimum erreicht wird. So ist zumindest meine Vermutung, die in der Ensemblestudie weiter getestet werden soll. Ich kann allerdings hier noch eine Struktur zeigen, bei der der Standard-Ansatz das Optimum erreicht, während der Piecemeal-Ansatz dies nicht tut:

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/standard_better.png}
  \caption{Piecemeal erreicht das globale Optimum nicht\label{fig:standard_better}}
\end{figure}

Aus dem genannten Grund kann der Piecemeal-Ansatz nie $s1$ und $s2$ in die Theorie aufnehmen und legt sich schliesslich in der finalen Theorie auf einen einzelnen Satz in den initialen Überzeugungen fest, während der Standard-Ansatz schon im ersten Schritt die optimale Theorie $\{s1, s2\}$ findet und auch beibehält. Das Beispiel enthält übrigens aus einem bestimmten Grund so viele Sätze, die aus $\{s1, s2\}$ folgen. Das Desideratum der Systematizität muss entweder anders definiert, oder ihm muss weniger Gewicht zugestanden werden. Ich werde im nächsten Absatz weiter darauf eingehen. An dieser Stelle soll nur gesagt sein, dass die in Abbildung \ref{fig:standard_better} abgebildete Struktur ohne $s6$ nicht das gleiche globale Optimum hätte. Die globalen Optima wären jeweils ein einzelner Satz der initialen Überzeugungen als finale Überzeugung und als finale Theorie der gleiche Satz. Dies würden wir intuitiv wohl nicht als Optimum bezeichnen.

\paragraph{Kritik an der Systematizität}
Das Desideratum der Systematizität ist jenes mit dem höchsten Gewicht. Die Systematizität $S$ einer Theorie $T$ ist gemäss \cite[S. 465]{beisbart_making_2021} wie folgt definiert:
$$
S(T) := 1- \left(\frac{\lvert T \rvert -1}{\lvert \overline{T} \rvert}\right)^2
$$

Die Anzahl der Sätze in der Theorie ($\lvert T \rvert$) -- 1 geteilt durch die Anzahl an Sätzen im Inhalt der Theorie ($\lvert \overline{T} \rvert$) wird monoton fallend normalisiert, was darauf hinausläuft, dass die Systematizität für Theorien mit einem Satz immer 1 beträgt. In \cite[S.~447]{beisbart_making_2021} wird die Systematizität als die Einfachheit einer Theorie beschrieben und ein Beispiel einer Theorie gemacht, welche nur einen Satz enthält, deren Inhalt aber aus vielen Sätzen besteht. Diese sei eine sehr systematische Theorie. Das stimmt zwar, lenkt aber vom Fakt ab, dass es in diesem Fall egal ist, wie viele Sätze eine Theorie mit einem einzigen Prinzip im Inhalt enthält. Die Theorie erhält in jedem Fall volle Systematizität. Dies führt dazu, dass 1007 von den 1200 (84~\%) zufällig generierten Kombinationen von initialen Überzeugungen mit einer dialektischen Struktur bestehend aus nur einem Satz zur optimalen Theorie haben. Da stellt sich die Frage, ob dieses Desiderat so richtig definiert beziehungsweise gewichtet ist.

\subsection{Erreichen des globalen Optimums}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/global_optima_standard_piecemeal.png}
  \caption{Erreichen eines globalen Optimums für beide Ansätze insgesamt. (x-Achse: Gesamtmenge der Sätze, y-Achse: erreichte globale Optima in \%) \label{fig:GlobOptPoolsizeLine}}
\end{figure}

Das globale Optimum beschreibt verschiedene mögliche Kombinationen von Theorie und Überzeugungen für eine gegebene dialektische Struktur und initiale Überzeugungen, welche den Wert der Achievement-Funktion maximieren. In den meisten Fällen gibt es mehrere solcher Kombinationen. Um die globalen Optima zu finden, werden alle möglichen Kombinationen von Überzeugungen und Theorien miteinander verglichen. Wird das generierte Ensemble anhand der erreichten Fixpunkten gemessen und dabei nach der Grösse der Satzmenge und den beiden Ansätzen unterschieden, so erhält man das Bild, welches Grafik \ref{fig:GlobOptPoolsizeLine} abbildet.

Abbildung \ref{fig:GlobOptPoolsizeLine} zeigt anschaulich, dass mit steigender Anzahl von Sätzen in der Satzmenge die Trefferquote beider Ansätze sinkt. Dies ist grundsätzlich zu erwarten. Jedoch konnten die Werte von 88~\%--95~\%, wie sie \cite[S.~455]{beisbart_making_2021} erreichten, nicht erreicht werden. Dies mag daran liegen, dass im vorliegenden Ensemble zufällige dialektische Strukturen generiert wurden, während bei \cite{beisbart_making_2021} die Gewichtung der Desiderata verändert und immer dieselben Strukturen untersucht wurden. Dennoch überrascht es, dass der Standard-Ansatz nie über 70~\% der globalen Optima trifft.

Die beiden Linien der Grafik verlaufen -- bis auf zwei Ausreisser -- relativ parallel, wobei sich der Abstand zwischen den beiden Ansätzen bei zunehmender Gesamtmenge an Sätzen zu verkleinern scheint. Jedoch ist das reine Spekulation, denn zum einen handelt es sich um sehr wenige Datenpunkte und man müsste die Grafik für grössere Satzmengen weiter führen und zum anderen gibt es die beiden Ausreisser von ca. 20~\%, die möglicherweise dem Zufall zuzuschreiben sind. Denn schlussendlich gibt es pro Gesamtmenge der Sätze nur 100 verschiedene dialektische Strukturen -- 50 mit Argumenten mit einer Prämisse und 50 mit solchen die 2 Prämissen erlauben. In Grafik \ref{fig:GlobOptPoolsizeLineOnePrem} möchte ich nun nur die dialektischen Strukturen betrachten, welche nur Argumente mit einer Prämisse enthalten.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/global_optima_standard_piecemeal_1prem.png}
  \caption{Erreichen eines globalen Optimums für beide Ansätze mit einprämissigen Argumenten. (x-Achse: Gesamtmenge der Sätze, y-Achse: erreichte globale Optima in \%) \label{fig:GlobOptPoolsizeLineOnePrem}}
\end{figure}

Bei Abbildung \ref{fig:GlobOptPoolsizeLineOnePrem} fällt auf, dass der Standard-Ansatz grundsätzlich etwas besser funktioniert als in der vorherigen Abbildung, der Piecemeal-Ansatz aber mal besser mal schlechter funktioniert.


\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/global_optima_standard_piecemeal_2prem.png}
  \caption{erreichen eines globalen Optimums für beide Ansätze mit zweiprämissigen Argumenten. (x-Achse: Gesamtmenge der Sätze, y-Achse: erreichte globale Optima in \%) \label{fig:GlobOptPoolsizeLineTwoPrem}}
\end{figure}

In Darstellung \ref{fig:GlobOptPoolsizeLineTwoPrem}, die Strukturen zeigt, die auch Argumente enthalten, welche zwei Prämissen haben, fällt auf, dass die Werte extrem nah beieinander liegen. Mit einer grossen Ausnahme: die Prozesse mit 9 verschiedenen Sätzen in der dialektischen Struktur. Bei den Piecemeal-Prozessen verändert sich der Prozentsatz der erreichten globalen Optima nur ein wenig. Beim Standard-Ansatz jedoch erreichen plötzlich nur noch 20\% der Prozesse ein globales Optimum. Der Anteil der globalen Optima mit nur einem Satz in der Theorie ist nicht höher als bei anderen Satzgrössen. In der folgenden Grafik werden die bisherigen Grafiken kombiniert, um zu sehen, ob sich weiteres herausfinden lässt.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{erreichen eines Globalen Optimums aufgeteilt nach Poolsize}
  \caption{Erreichen eines globalen Optimums aufgeteilt nach Gesamtzahl der Sätze (x-Achse: Gesamtmenge der Sätze, y-Achse: erreichte globale Optima in \%) \label{fig:GlobOptPoolsize}}
\end{figure}

Um mit Grafik \ref{fig:GlobOptPoolsize} noch einmal zusammenzufassen: Der Standard-Ansatz erreicht zwar öfter ein globales Optimum, dies jedoch nur, weil er bei Argumenten mit nur einer Prämisse wesentlich besser funktioniert als mit zwei Prämissen. So erreicht er bei Argumenten mit einer Prämisse und 5 Sätzen in der Gesamtmenge zu 80 \% das globale Optimum im Vergleich zu Argumenten mit zwei Prämissen, wo es nur 56\% sind. Schaut man sich die zweiprämissigen Argumente an, so erreicht Piecemeal schon ab einer Poolgrösse von 6 Sätzen öfter ein globales Optimum als der Standard-Ansatz.

\subsection{Vergleich der Achievements zwischen den Ansätzen}

Wie gut ein Überlegungsgleichgewichtszustand -- bzw. der erreichte Fixpunkt eines RE-Prozesses -- ist, wird am Wert der Achievement-Funktion des Fixpunktes gemessen. Wenn der Piecemeal-Prozess einen höheren Achievement-Wert erreicht als der Standard-Ansatz, so wird er in diesem Absatz als besser bezeichnet.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{höheres Achievement aufgeteilt nach initialen Commitments}
  \caption{höheres Achievement aufgeteilt nach initialen Überzeugungen (x-Achse: Anzahl an initialen Überzeugungen, y-Achse: Anteil der Strukturen mit höherem Achievement als das Pendant) \label{fig:höheres Achievement aufgeteilt nach initialen Commitments}}
\end{figure}

Auf Abbildung \ref{fig:höheres Achievement aufgeteilt nach initialen Commitments} fällt auf, dass ein Piecemeal-Prozess, der weniger als vier initiale Überzeugungen hat, fast nie besser ist, als der entsprechende Prozess mit derselben dialektischen Struktur. Dies lässt sich sehr gut auf der falschen Reihenfolge der Anpassungen (vgl. Abs. \ref{found problems}) und den Fakt, dass die initiale Theorie die leere Menge ist, zurückführen. Wie schon anhand eines Beispiels erklärt wurde, enden Piecemeal-Prozesse mit einem Satz in den initialen Überzeugungen immer mit einem mehr oder weniger zufälligen Fixpunkt. Dieser Effekt scheint sich erst ab 4 Sätzen in den initialen Überzeugungen langsam aufzuheben. Es ist also anzunehmen, dass, wenn die Reihenfolge der Anpassungen korrigiert würde, der Piecemeal-Prozess wesentlich besser funktionieren würde.

\subsubsection{zweiprämissige Strukturen}

Ich habe die Vermutung geäussert, dass der Piecemeal-Ansatz bei Strukturen, die Argumente enthalten, welche zwei oder mehr Prämissen enthalten, nicht gut funktioniert. Um dies zu verbildlichen wurden die Grafiken \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse} und \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf max 2 Prämissen} erstellt. In \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse} werden die Standard- und Piecemeal-Prozesse verglichen. Die \textcolor{teal}{hellblaue Säule} zeigt den Anteil an Standard-Prozessen, die ihre Piecemeal-Pendant im Achievement übertrafen. Die \textcolor{blue}{blaue Säule} zeigt den Anteil an Piecemeal-Prozessen an, die einen höheren Wert der Achievementfunktion erreichten. Die \textcolor{purple}{violetten Säulen} zeigen den Anteil an, bei dem beide Prozesse gleich gute Leistung gezeigt haben.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse}
  \caption{höheres Achievement aufgeteilt nach Gesamtzahl der Sätze begrenzt auf ein-Prämisse-Strukturen\label{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse}}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{höheres Achievement aufgeteilt nach Poolsize begrenzt auf max 2 Prämissen}
  \caption{höheres Achievement aufgeteilt nach Gesamtzahl der Sätze begrenzt auf 2 Prämissen-Strukturen\label{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf max 2 Prämissen}}
\end{figure}

In den Grafiken \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse} und \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf max 2 Prämissen} ist erkennbar, dass der Piecemeal-Ansatz deutlich besser funktioniert, wenn die Argumente 2 Prämissen haben können und die Grösse des Satzpools etwas grösser ist als 5. Dies widerspricht meiner ursprünglichen Vermutung. Es scheinen mehrere Faktoren zu sein, die zu diesem überraschenden Ergebnis geführt haben: Die meisten Entdeckungen, die ich bis zu diesem Punkt gemacht habe, spielen eine Rolle. Allen voran das Problem mit der Systematizität. Denn, 465 von 594 Strukturen mit mindestens einem Argument, das zwei Prämissen hat, haben ein globales Optimum mit nur einem Satz in der Theorie. Dies entspricht 78~\% und damit etwas weniger als dem Schnitt von 83~\% von allen Strukturen. Bei dialektischen Strukturen, die nur einprämissige Argumente enthalten, sind es sogar 542 von 606 globalen Optima und damit 89~\%, die nur einen Satz in der Theorie enthalten. Allein die Anzahl an globalen Optima mit nur einem Satz kann den Unterschied also nicht erklären. Wenn man sich weiter anschaut, in wie vielen Fällen der Standard-Ansatz einen Fixpunkt erreicht, der mehr als einen Satz in der Theorie enthält, so sind dies bei ein-Prämisse-Strukturen 106, bei den Zwei-Prämissen-Strukturen allerdings 228. In all diesen Fällen kann das Optimum nicht erreicht worden sein. Piecemeal-Prozesse erreichen in ein-Prämissen-Strukturen 35 Mal eine Theorie mit mehr als einem Satz, bei zwei-Prämissen-Strukturen sind es sogar nur 9 Mal. Zwar erreichen auch 189 der 465 betrachteten Piecemeal-Prozesse das Globale Optimum nicht, aber trotzdem erklärt dies die besseren Achievementwerte sehr gut. Aus dem Genannten folgt, dass der Standard-Ansatz bei Ein-Prämisse-Strukturen eher Lösungen generiert, die mehr als einen Satz in der Theorie haben und deswegen schlechter funktioniert als bei Zwei-Prämissen-Strukturen im Vergleich mit Piecemeal-Prozessen.

\paragraph{leere Anfangstheorie} Eine Frage, die noch nicht geklärt wurde, ist, warum Piecemeal-Prozesse konsequent Theorien mit nur einem Satz erreichen. Dadurch, dass im Piecemeal-Ansatz die initiale Theorie als leere Menge definiert ist und jeweils nur ein Satz dazu kommt, ist garantiert, dass jeder Piecemeal-Prozess mindestens einmal im Verlauf des Prozesses eine Theorie mit einem Satz hat. Der in Abschnitt \ref{found problems} beschriebene Fehler in der Reihenfolge der Anpassungen im Programm dürfte ausserdem dazu beitragen, auf eine Theorie mit nur einem Satz zu kommen und dabei zu bleiben: Denn dadurch wird ein zufälliger Satz der Überzeugungen entfernt und aus weniger Überzeugungen folgt auch, dass eher weniger Sätze in der Theorie sind.

\section{Fazit}
Das anwendbare Modell des Überlegungsgleichgewichts von \citeauthor{beisbart_making_2021} treibt die philosophische Arbeit in diesem Bereich ein grosses Stück voran. Ich hoffe, mit meiner Arbeit einen kleinen Beitrag geleistet zu haben. Die vorliegende Arbeit hat gezeigt, dass grosse Probleme bei der praktischen Umsetzung des klassischen Ansatzes des Überlegungsgleichgewichts bestehen, da der erforderliche Aufwand enorm ist. Dieser ist so gross, dass es einerseits für Personen kaum nachvollziehbar ist, andererseits ist er selbst für Computer bei komplexeren dialektischen Strukturen schnell nicht mehr anwendbar. Eine Lösung könnte der Piecemeal-Ansatz sein. In dieser Arbeit wurde eine Version davon ausformuliert und klar definiert. Danach wurde auch bei diesem eine Schwäche aufgezeigt: Bei Argumenten, die mehr als eine Prämisse haben, werden Schwierigkeiten entstehen. Um dies zu beheben, muss man davon abrücken, nur einen einzelnen Satz hinzuzufügen beziehungsweise zu entfernen. Dies würde dann aber nicht mehr dem Gedanken entsprechen, den \cite{goodman_fact_1983} im Sinn hatte, als er über Piecemeal-Ansätze sprach. Des Weiteren bleibt auch die Frage der Anfangstheorie in einem Piecemeal-Ansatz offen. Diese Arbeit soll gezeigt haben, dass die leere Menge nicht die beste initiale Theorie ist. Ob aber der Vorschlag im Anhang besser ist, muss noch überprüft werden.
Das grösste Problem des dieser Arbeit zugrunde liegenden Modells besteht aber in der Festlegung und Gewichtung des Desideratums der Systematizität. Es wurde gezeigt, dass der Status Quo bei nicht allzu weit hergeholten dialektischen Strukturen nicht intuitiv nachvollziehbare Ergebnisse liefert. Dies stellt aber überhaupt die Gewichtung und Definition der Desiderata infrage. Klar ist, dass die Desiderata in \cite{beisbart_making_2021} nicht einfach aus der Luft gegriffen sind, sondern die Arbeit vieler Philosophen und Philosophinnen in die Festlegung geflossen ist. Dies wirft die Frage auf, ob es eventuell nie möglich sein wird, Desiderata zu entwerfen, die in allen Strukturen nachvollziehbare globale Optima liefern.

Das Feld des Überlegungsgleichgewichts ist weit geöffnet und es bieten sich für Philosophen und Philosophinnen Möglichkeiten, weitere Erkenntnisse zu gewinnen. Vielleicht wird es in nicht ferner Zukunft möglich sein, eine dialektische Struktur für eine reelle philosophische Debatte -- beispielsweise mit \href{https://argdown.org/}{Argdown} -- abzubilden und sich danach mittels Software auf eingegebene initiale Überzeugungen ein Überlegungsgleichgewicht vorschlagen zu lassen. Dadurch können fruchtbare Diskussionen entstehen, die Philosophinnen und Philosophen neue Erkenntnisse und Ideen bringen.


\newpage
\printbibliography

\newpage 
\listoffigures

\newpage

\section{Anhang}
\subsection{ Vorschlag für eine initiale Theorie: Analyse der Inferenzbeziehungen} \label{better-first-theory}
Im traditionellen Ansatz wird im initialen Zustand die leere Menge als erste Theorie angenommen. Ich möchte einen alternativen Vorschlag vorstellen, wie eine erste Theorie gefunden werden könnte. Er entstand durch die Überlegung, wie Personen den Prozess wohl intuitiv durchführen würden. Die Idee ist, dass man sich die Inferenzbeziehungen der Argumente anschaut, welche die ersten Überzeugungen beinhalten. Aufgrund der Inferenzbeziehungen zwischen Sätzen, kann klug entschieden werden, welche Sätze sich eher als Theorien lohnen. Es gilt zu beachten, dass bei der Analyse der Inferenzbeziehungen ignoriert wird, dass Sätze auch Prinzip für sich selbst sein können. Dies dürfte aber kein Problem sein bei der Erstellung einer ersten Theorie.

\paragraph{Generierung der Theorie}
Ausgehend von der Menge von Überzeugungen $C_0$ wird eine Theorie $T_0$ wie folgt erzeugt. Wann immer eine Menge mit Subskript angegeben wird, ist damit der Wert in der Menge mit dem Index des Subskripts gemeint.
\begin{enumerate}
    \item Zu Beginn des Prozesses hat der Index $z$ -- welchen wir benötigen werden, um durch die Mengen in $P$ zu iterieren -- den Wert Null. Die Menge $S$ -- welche unsere Theoriekandidaten enthält -- entspricht am Anfang der leeren Menge. $S = \{\}$ $z = 0$
    \item Die Menge $P$ wird aus $C_0$ generiert. Sie enthält alle Permutationen von $C_0$. $P$ ist indexiert.
    $$
        P := \{ P_i : P_i \text{ ist eine Permutation von } C_0\}
    $$
    \item \label{i1} Die erste Überzeugung aus der Menge in $P_z$ wird ausgewählt: $a = 0$ (Index 0)
    \item \label{i2} Falls die Menge $S_z$ leer ist: Für die aktuell ausgewählte Überzeugung $P_z^a$ werden alle Prinzipien gesucht, aus welchen die ausgewählte Überzeugung folgt, die jedoch nicht mit der ausgewählten Überzeugung identisch sind. Jedes gefundene Prinzip eröffnet eine neue Menge und diese Mengen werden $S_z$ hinzugefügt.
    
    Falls $S_z$ nicht leer ist: Jedes für $P_z^a$ gefundene Prinzip wird zu den Mengen in $S_z$ hinzugefügt, falls die entstehende Menge konsistent ist und das Prinzip nicht schon enthalten ist.
    \item \label{i3} Falls $P_z^a$ noch nicht das letzte Element aus $P_z$ ist, wird die nächste Überzeugung aus $P_z$ ausgewählt (indem a um Eins inkrementiert wird) und zu Schritt \ref{i2} gesprungen.
    $$
        a = a + 1
    $$
    \item \label{i4} Falls $z < \lvert P \rvert$ : $z$ wird um eins inkrementiert: $z = z + 1$ und zu Schritt \ref{i1} gesprungen.
    \item \label{i5} In den Mengen $S$ werden die Mengen, welche die gleichen Elemente enthalten, zu einer reduziert. Alle $S$ Mengen werden mittels Achievement-Funktion $Z$ überprüft.
    \item \label{i6} Die Theorie, welche den höchsten Wert bei $Z$ erreicht, wird zur Theorie $T_0$. Falls mehrere Theorien den höchsten Wert erreichen, wird eine Theorie zufällig ausgewählt.
\end{enumerate}

\paragraph{Beispiel}
Beispielhaft kann auch hier wieder die Struktur, welche auf Abbildung \ref{fig:classset-initial1} illustriert ist, dienen. Die initialen Überzeugungen sind auf dieser Abbildung die folgenden: $\{s3, s4, s5\}$. Im ersten Schritt wählen wir $s3$ und finden $s1$ als mögliches Prinzip für $s3$ im zweiten Schritt. Da $S_0$ noch leer ist, fügen wir $s1$ hinzu. Dann suchen wir ein Prinzip für $s4$, wobei wir wieder auf $s1$ stossen und dieses nicht ein zweites Mal zu $S_0$ hinzufügen. Danach folgt unsere nächste und letzte Überzeugung $s5$. Für $s5$ finden wir nun zwei mögliche Prinzipien: $s1$ und $s2$. Nun ergäben sich zwei Mengen in $S_0$: $\{s1\}$ und $\{s1, s2\}$. Da $\{s1, s2\}$ aber inkonsistent ist, wird sie weggelassen. Als Nächstes starten wir den Prozess erneut, diesmal fangen wir aber mit $s4$ als erster Überzeugung an, für die wir Prinzipien suchen. Der Prozess verläuft analog zum ersten Durchgang, und am Ende haben wir eine Menge $S_1 = \{s1\}$. Für den dritten und letzten Durchgang mit $s5$ als Startüberzeugung ergibt sich aber ein anderes Bild: Zu $S_2$ werden die beiden Prinzipien $s1$ und $s2$ als einzelne Elemente hinzugefügt. Bei der Suche nach einem Prinzip für $s4$ und analog für $s3$ wird jeweils $s1$ gefunden. Zur ersten Menge in $S_2$ wird $s1$ nicht hinzugefügt, weil es schon enthalten ist, zur zweiten Menge nicht, weil die resultierende Menge $\{s1,s2\}$ inkonsistent wäre. Somit ist $S_1 = \{{s1}, {s2}\}$. Die Mengen in $S_0$, $S_1$ und $S_3$ werden nun zusammengeführt, wobei die Doppelungen wieder gestrichen werden können. Somit ergeben sich folgende Kandidaten, für die ihr $Z$-Wert verglichen werden muss: $\{\{s1\}, \{s2\}\}$.

\paragraph{Aufwand}
Da alle Permutationen von $C_0$ durchlaufen werden müssen, umfasst die Methode relativ viele Schritte. Allerdings gäbe es vielleicht eine Möglichkeit, nicht über alle Permutationen iterieren zu müssen und beispielsweise nur mit jedem Element aus $C_0$ einmal anzufangen. Dies bedarf aber weiterer Forschung und ist nicht Gegenstand dieser Arbeit.

\newpage
\subsection{Selbstständigkeitserklärung}

Ich erkläre hiermit, dass ich diese Arbeit selbstständig verfasst und keine anderen als die angegebenen Quellen benutzt habe. Alle Stellen, die wörtlich oder sinngemäss aus Quellen entnommen wurden, habe ich als solche gekennzeichnet. Mir ist bekannt, dass andernfalls der Senat gemäss Artikel 36 Absatz 1 Buchstabe r des Gesetzes vom 5. September 1996 über die Universität zum Entzug des auf Grund dieser Arbeit verliehenen Titels berechtigt ist.

Für die Zwecke der Begutachtung und der Überprüfung der Einhaltung der Selbständigkeitserklärung bzw. der Reglemente betreffend Plagiate erteile ich der Universität Bern das Recht, die dazu erforderlichen Personendaten zu bearbeiten und Nutzungshandlungen vorzunehmen, insbesondere die schriftliche Arbeit zu vervielfältigen und dauerhaft in einer Datenbank zu speichern sowie diese zur Überprüfung von Arbeiten Dritter zu verwenden oder hierzu zur Verfügung zu stellen.

\vspace{30mm}

\noindent\begin{tabular}{ll}
\makebox[2.5in]{\hrulefill} & \makebox[2.5in]{\hrulefill}\\
Sebastian Flick & Datum\\
\end{tabular}

\end{document}


%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{piecemeal Inferenzanalyse}

Eine interessante Alternative zur Inferenzanalyse ist die Idee, die Anpassung der Theorie auch schrittweise zu machen. Dies würde einerseits einen weiteren piecemeal-Aspekt umsetzen und andererseits das Problem der Notwendigkeit der Permutation der Überzeugungen lösen. Die Theorieanpassung würde wie folgt aussehen:

\begin{enumerate}
    \item Die erste Überzeugung aus $C_i$ wird ausgewählt: $c_a = c_0$ (Index 0)
    \item Für die ausgewählte Überzeugung $c_a$ werden alle Prinzipien gesucht, welche die ausgewählte Überzeugung zum Inhalt haben. Jedes gefundene Prinzip wird $S$ hinzugefügt, wenn es nicht schon in der Menge enthalten ist.
    \item Falls $c_x$ noch nicht das letzte Element aus $C_i$ ist, wird die nächste Überzeugung aus $C_i$ ausgewählt und zu Schritt \ref{i2} gesprungen.
    \item Aus den Elementen in $S$ werden alle konsistenten Mengen gebildet.
    \item Diese Mengen werden mittels Achievement-Funktion $Z$ überprüft.
    \item Die Theorie, welche den höchsten Wert bei $Z$ erreicht, wird zu $T_{i+1}$ erklärt, falls ihr $Z$-Wert auch grösser ist als jener von $T_i$ -- Ansonsten wird $T_i$ zu $T_{i+1}$.
\end{enumerate}