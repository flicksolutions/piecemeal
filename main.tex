\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{csquotes}
\usepackage[ngerman=ngerman-x-latest]{hyphsubst}
\usepackage{color} %Zum stylen von \def
\usepackage[dvipsnames]{xcolor}

\definecolor{teal}{RGB}{124,214,253}
\definecolor{blue}{RGB}{94,100,255}
\definecolor{purple}{RGB}{116,62,226}

\usepackage{varwidth} %Zum stylen von \def
\usepackage{etoolbox} %Zum stylen von \def
\usepackage{amssymb} %Für die Mengensymbole
%\usepackage{svg}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{amsmath} %Zur Darstellung von Funktionen mit Fallunterscheidung
\usepackage{scrlayer-scrpage} %Kopf- und Fusszeile
\usepackage{titling} %Titel nach oben verschieben
\usepackage{amsfonts} %\mathcal
\usepackage{enumerate} %Für kleine römische Zahlen in Aufzählungen
\usepackage{hyperref}
\usepackage[normalem]{ulem} %für durchgestrichenen text
\newcommand{\stkout}[1]{\ifmmode\text{\sout{\ensuremath{#1}}}\else\sout{#1}\fi} %text durchstreichen auch in math-mode

%\usepackage{prettyref}
%\usepackage{apacite}
\usepackage[
backend=biber,
style=apa,
]{biblatex}
\addbibresource{references.bib}

%\usepackage{array,multirow}



%% Formatierung %%
\sloppy
\usepackage[dvipdfm]{geometry}
\setlength{\droptitle}{-10em}
\geometry{bottom=3.5cm, textwidth=15cm, headsep=15mm, top=5cm,head=15pt}
%%%%%%%%%%%%%%%%%%

%\usepackage{vaucanson-g}
%%  Kopf- und Fusszeile anpassen %%
\pagestyle{scrheadings} 

\ihead{\small{Bachelorarbeit}}
\ohead{\small{Sebastian Flick, Universität Bern}}
\cfoot{\thepage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcounter{std}
\setcounter{std}{1}

%% New Commands %%
\newcommand{\comment}[1]{{\color{red} #1}}

\definecolor{bg}{gray}{1}
\newcommand{\spec}[3]{
    \begin{flushleft}
    \mpar{\vspace{.5cm}#2}\colorbox{bg}{\hspace{.4cm}\parbox{\textwidth}{
        \begin{varwidth}{\dimexpr\linewidth-2\fboxsep}
            \vspace*{.2cm}
            \noindent{\textbf{#1 \ifstrempty{#2}{}{\textit{#2}: }}#3}
            \stepcounter{std}
        \end{varwidth}
    }}
    \end{flushleft}
}

\newcommand{\formula}[1]{\\$#1$}

\renewcommand{\L}{\Box}
\newcommand{\M}{\Diamond}
\newcommand{\qed}{\hspace{0.5cm}$\blacksquare$}

\newcommand\mpar[1]{\marginpar {\flushleft\sffamily\small #1}}
\setlength{\marginparwidth}{2cm}

%%%%%%%%%%%%%%%%%%%%

\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}

\newcommand{\bmt}{\begin{pmatrix}}
\newcommand{\emt}{\end{pmatrix}}

\title{Ein realistischeres Modell des Überlegungsgleichgewichts}
\author{Bachelorarbeit von Sebastian Flick, 16-121-014\\Betreut von Prof. Dr. Dr. Claus Beisbart\\Universität Bern}


\date{\today}

\begin{document}
\maketitle
\section{Einführung}
In dieser Arbeit geht es um ein Modell, welches das Überlegungsgleichgewicht umsetzt. Für diese Methode zur Rechtfertigung, welches seit den Siebzigerjahren des letzten Jahrhunderts von vielen Philosophen vertreten und von ähnlichen vielen kritisiert wurde, entwickelten \citeauthor{beisbart_making_2021} nämlich ein exaktes Modell.
Das Ziel der Arbeit ist es, innerhalb dieses Modells einen kleinen, aber wichtigen Aspekt zu untersuchen: die Theorie- und Überzeugungsanpassung. Konkret soll ein Piecemeal-Ansatz formuliert werden. Dieser soll Anpassung von Überzeugungen und Theorien umsetzbarer und nachvollziehbarer zu machen. Um herauszufinden, wie Theorien und Überzeugungen in den jeweiligen Anpassungsschritten angepasst werden müssen, wird bisher einfach jede mögliche und konsistente Kombination von Prinzipien bzw. Überzeugungen überprüft. Dies ist einerseits nicht, was \citeauthor{goodman_fact_1983} im Sinn hatte, als er Reflective Equilibrium beschrieb - er sprach von einzelnen Sätzen, welche zur Theorie bzw. zu den Überzeugungen addiert oder subtrahiert würden \autocite{goodman_fact_1983}, andererseits ab einer gewissen Grösse des zu behandelnden Themas schlicht nicht umsetzbar. Ausserdem ist es wichtig einen intuitiven Weg zu finden, wie die Änderungen an Theorie und Überzeugungen gemacht werden - Denn auch von diesem Faktor hängt die Glaubwürdigkeit der Methode ab. Ein möglicher Weg ist ein Piecemeal-Ansatz, welcher Überzeugungen und Prinzipien stückweise zu vorhanden Überzeugungen bzw. Theorien hinzufügt. Ich setze mir zum Ziel, einen bestimmten Piecemeal-Ansatz auszuformulieren. Wenn in der Folge der Arbeit von einem Piecemeal-Ansatz die Rede ist, ist mein ausformulierter Ansatz gemeint. Um herauszufinden, ob sich die Anwendung des Piecemeal-Ansatzes lohnt, werde ich eine Ensemblestudie generieren und die vorhandenen Daten analysieren, um zu verstehen, unter welchen Bedingungen der Piecemeal-Ansatz tatsächlich besser ist, als der traditionelle Ansatz.

Ich werde zum Beginn der Arbeit die Methode Reflective Equilibrium vorstellen und eine kleine historische Einführung in das Thema geben. Danach werde ich den Piecemeal-Ansatz detailliert vorstellen. Ich werde sie innerhalb des Modells von \citeauthor{beisbart_making_2021} definieren und zeigen, dass der Ansatz unter bestimmten Bedingungen besser ist als der konventionelle. Ausserdem werde ich einen Vorschlag für die Erstellung einer ersten Theorie vorbringen.

\section{Reflective Equilibrium und seine Ursprünge}

Bei Reflective Equilibrium handelt es sich um eine Methode zur Rechtfertigung unserer Überzeugungen. Sie ist als Instrument zu verstehen, um zu gerechtfertigter Meinung zu kommen. Wir pflegen unsere anfänglichen Überzeugungen - die eine gewisse anfängliche Glaubwürdigkeit haben - in ein System von Prinzipien ein und passen beides aneinander an. Am Ende dieser Anpassungen erhalten wir einen Gleichgewichtszustand. Aus dem System von Prinzipien folgen - einige oder alle - unsere Überzeugungen, die wir anfangs für plausibel hielten. Dadurch ist die Überzeugung gerechtfertigt. Es gibt verschiedene Auffassungen darüber, wie Reflective Equilibrium funktioniert - oder funktionieren soll - und wie es zu verstehen ist \autocite{sep-reflective-equilibrium}.
Ich werde mich in dieser Arbeit aber vor allem an die Interpretation, die auch in \cite{beisbart_making_2021} vertreten wird, halten. Dies beinhaltet, dass Reflective Equilibrium - wie eingangs beschrieben - eingesetzt werden kann zur Beantwortung von Fragen in einem Gebiet und somit nach Scanlon deliberativ ist. Eine rein deskriptive Auffassung, bei welcher durch das Reflective Equilibrium lediglich herausgefunden werden kann, welche Überzeugungen eine Person hat, wird hier nicht weiterverfolgt \autocite[S.~143]{freeman_rawls_2002}. Für Scanlon ist der Prozess kein rein quantitatives Unterfangen. Das Individuum, welches einen RE-Prozess durchführt, merkt beispielsweise durch welche Prinzipien ihre Überzeugung gestützt wird und kann sich dann spontan dazu entscheiden, die Überzeugung aufzugeben. Für ihn ist somit ausgeschlossen, dass der Prozess durch ein mathematisches Modell abgebildet werden kann. \autocite[S.~148]{freeman_rawls_2002}
Eine weitere Distinktion in den verschiedenen Interpretationen von Reflective Equilibrium, ist die Unterscheidung zwischen \textit{wide} (breit) und \textit{narrow} (schmal) Reflective Equilibrium: Diese wurde von \citeauthor{daniels_wide_1996} ins Spiel gebracht. Das Modell von \citeauthor{beisbart_making_2021} bildet ein \textit{narrow} RE ab. Denn bei einem \textit{wide} RE würden Hintergrund-Theorien miteinbezogen werden und diesen wurde im Modell kein Platz eingeräumt. Hintergrundtheorien können während des Prozesses nicht verändert werden und geniessen einen Sonderstatus. Durch eine Einschränkung der Argumente - diese müssen mit etwaigen Hintergrundtheorien konsistent sein - könnte das Modell aber auch innerhalb eines \textit{wide} RE funktionieren. \autocite[S.~459]{beisbart_making_2021}

Der Begriff Reflective Equilibrium wurde 1971 von John Rawls geprägt. In \autocite{rawls_theory_1971} erarbeitet er die Methode, um die \textit{original position} einer Gesellschaft zu rechtfertigen. In dieser überprüft man, ob die gewählten Prinzipien mit den in Betracht gezogenen Überzeugungen (betreffend der Gerechtigkeit) übereinstimmen oder diese in akzeptierbarer Weise erweitern. Wir haben gewisse Überzeugungen (über Gerechtigkeit) für die wir klare Intuitionen haben. Diese Überzeugungen können wir als Fixpunkte benutzen, um mit Prinzipien, welche diese Fixpunkte erklären, weitere Überzeugungen zu erklären, für die wir keine klaren Intuitionen haben. Durch die Beschreibung der \textit{initial situation} generieren wir Prinzipien, diese gleichen wir mit den Überzeugungen ab. Erklären die Prinzipien die Überzeugungen nicht, so kann man entweder die Überzeugungen anpassen oder aber die Prinzipien. Daraus entsteht - nach möglicherweise mehrmaliger Wiederholung - ein Reflective Equilibrium. Er beschreibt die Überzeugungen und Theorie als jeweils eine Einheit, diese werden auch als Einheit verändert. Ein Piecemeal-Ansatz - wie ich ihn später als Alternative vorschlagen werde - ist bei Rawls also nicht zu entdecken. Rawls verweist bei der Verwendung des Begriffs Reflective Equilibrium auf \cite{goodman_fact_1983}, welcher vor ihm über die Idee gesprochen hat, ihr aber noch keinen Namen gegeben hat. \autocite[S.~20]{rawls_theory_1971}

Bei Goodman ist  Piecemeal-Ansatz, beinei dem Theorie und Überzeugungen stückweise angepasst werden, zu entdecken:

\begin{quote}
    A rule is amended if it yields an inference we are unwilling to accept; an inference is rejected if it violates a rule we are unwilling to amend. \autocite[S.~64]{goodman_fact_1983}
\end{quote}

Er spricht also von einzelnen Prinzipien, welche abgeändert werden, statt von einer ganzen Theorie. Und von einzelnen Überzeugungen, die angepasst werden, wenn sie einem Prinzip widersprechen, dass wir nicht ändern wollen. Nicht alle Autoren, die sich zum Thema Reflective Equilibrium äussern, machen sich detaillierte Gedanken über die Anpassungsschritte. So scheint es beispielsweise bei \autocite{tersman_reflective_1993} unklar, ob er sich für einen Piecemeal-Ansatz ausspricht oder nicht. Wohl einfach, weil es nicht im Fokus seiner Arbeit lag. Es soll aber im Fokus der vorliegenden Arbeit liegen. Dazu fasse ich zuerst kurz das Modell in \autocite{beisbart_making_2021} kurz vor und lege den Fokus auf die Änderungen an einem System, da dies der Teil ist, der uns am meisten interessiert.

\section{Das konventionelle System}

Das Modell von \citeauthor{beisbart_making_2021} geht von einer Menge von Sätzen aus, die für das Thema, über welches man ein RE erhalten will, relevant sind. Diese Menge ist unter Negation geschlossen. Das heisst, wenn sie einen Satz beinhalten, so beinhaltet sie auch dessen Negation.
Der Prozess, welcher abgebildet wird, beginnt mit einem initialen epistemischen Zustand.

\paragraph{Der epistemische Zustand} Dieser epistemische Zustand besteht aus Theorie und einer Menge von Überzeugungen. Die Theorie wiederum besteht aus einzelnen Prinzipien. Prinzipien können beliebige Sätze aus der Satzmenge sein. Der Inhalt einer Theorie ist die Menge von Sätzen, die aus den Prinzipien folgt. So kann nun also jeder Satz in einem Satzpool Prinzip, Inhalt und/oder Überzeugung sein. Sätze folgen aus sich selbst, sodass im Inhalt einer Theorie immer auch die Prinzipien sind. In Abbildung \ref{fig:smallset} ist die Menge aller Sätze folgende: $\{s1,s2,\neg s1, \neg s2\}$. Durch den Pfeil ist angedeutet, dass $s2$ aus $s1$ folgt. Dies ist das einzige Argument in der Struktur. Zum initialen Zustand gehört nun also eine Menge von Überzeugungen. Wir wählen $\{s2\}$. Ausserdem gehört eine initiale Theorie dazu. Diese ist im Standard-Modell die leere Menge. Der Inhalt der leeren Menge ist ebenfalls die leere Menge - Das heisst aus der leeren Menge folgen keine Sätze. Angenommen $\{s1\}$ wäre die Theorie, so wäre $s1$ das einzige Prinzip der Theorie und $\{s2\}$ der Inhalt der Theorie.

\begin{figure}[ht]
  \centering
  \includegraphics{figure1}
  \caption{Eine kleine Menge von Sätzen\label{fig:smallset}}
\end{figure}

Hat man einen initialen epistemischen Zustand, folgt als erster Schritt die Änderung der Theorie und danach die Änderung der Überzeugungen. Diese werden so lange angewendet, bis eine Haltebedingung zutrifft.\autocite[S.~449]{beisbart_making_2021}

Für die Änderung der Theorie werden verschiedene Theoriekandidaten miteinander verglichen. Ich werde später darauf zu sprechen kommen, wie diese gefunden werden. Die Kandidaten werden mittels einer Achievement-Funktion überprüft.

\paragraph{Die Achievement-Funktion} \label{achievement-funktion}
Die Achievement-Funktion untersucht einen epistemischen Zustand auf die Kriterien der \textit{Kohärenz (Account)}, der \textit{Systematizität (Systematicity)} und des \textit{Respekts (Faithfulness)}. \textit{Kohärenz} beschreibt, wie sehr die Theorie die Überzeugungen erklärt. Dabei wird der Wert der Kohärenz verringert, für jede Überzeugung, welche mit der Theorie inkonsistent ist, für jede, die nicht im Inhalt der Theorie ist und für jeden Satz im Inhalt der Theorie, welcher keine Überzeugung ist. Vor allem dieser letzte Punkt scheint etwas kontraintuitiv. Warum sollte es schlechter für die Kohärenz sein, wenn eine Theorie mehr erklärt, als die gesuchten Überzeugungen? \citeauthor{beisbart_making_2021} erklären dies damit, dass dies einen Druck dahingehend erzeugt, dass die Überzeugungen alle Sätze im Inhalt der Theorie bei den Anpassungsschritten der Überzeugungen aufnehmen.
\textit{Systematizität} bezieht sich nur auf die Theorie eines epistemischen Zustandes. Je mehr Sätze im Inhalt einer Theorie sind im Verhältnis zu den Sätzen in der Theorie, umso systematischer ist die Theorie. Eine Theorie mit einem Satz, welcher vier Sätze im Inhalt der Theorie hat, ist also systematischer, als eine Theorie, mit einem Satz, welche nur sich selbst im Inhalt der Theorie hat.
\textit{Respekt} bezieht sich nur auf die Überzeugungen eines epistemischen Zustandes. Der Respekt der Überzeugungen wird schlechter, für jede initiale Überzeugung, welche negiert in den Überzeugungen vorkommt und für jede initiale Überzeugung, die nicht vorkommt.

\paragraph{Gewichtung} Diese drei Desiderata sind unterschiedlich gewichtet. Dies ist wichtig, da die Desiderata einen epistemischen Zustand oft in unterschiedliche Richtungen ziehen. Beispielsweise wird ein epistemischer Zustand kohärenter, wenn man alle Überzungen entfernt, die nicht Teil des Inhalts sind. Darunter leidet allerdings der Respekt. Deshalb müssen die Desiderata unterschiedlich gewichtet werden, damit überhaupt Fortschritt erzielt werden kann. Ich verwendete für meine Ensemblestudie lediglich die Standard-Gewichte (Kohärenz: 0.35, Respekt: 0.10, Systematizität: 0.55) - Das Modell erlaubt aber auch andere Gewichtungen, was ich auch vorschlagen werde. \autocite[S.~448]{beisbart_making_2021}

\paragraph{Konsistenz\label{konsistenz}}
Ich habe bisher den Begriff der Konsistenz schon einige mal verwendet, ohne genau zu definieren, was dieser bedeutet. Das möchte ich nun ändern. Konsistenz bedeutet in der Logik, dass eine Menge von Sätzen gleichzeitig wahr sein kann. Dass also aus ihr kein Widerspruch abgeleitet werden kann. In dieser Arbeit spielen zwei Arten der Konsistenz eine Rolle: minimale Konsistenz und volle Konsistenz. Bei der minimalen Konsistenz wird lediglich gefordert, dass die Menge von Sätzen nicht einen Satz und gleichzeitig dessen Negation enthält. Bei voller Konsistenz, welche von Theorien gefordert wird, werden die inferenziellen Beziehungen von Sätzen miteinbezogen. Wenn also bspw. der Satz $s3$ aus $s1$ folgt und aus $s2$ folgt $\neg s3$, so wäre die Menge von Sätzen ${s1,s2}$ inkonsistent, denn aus ihr folgt $s3$ und $\neg s3$ und dies ist ein Widerspruch. Siehe dazu Abbildung \ref{fig:inconsistency}. Anders ausgedrückt kann man auch sagen, dass wenn von einer Theorie volle Konsistenz gefordert wird, so wird von Ihrem Inhalt minimale Konsistenz gefordert. Im Inhalt dürfen sich keine Sätze finden, deren Negationen sich auch darin finden.

\begin{figure}[ht]
  \centering
  \includegraphics{consistence.png}
  \caption{Möglichkeit der Inkonsistenz\label{fig:inconsistency}}
\end{figure}

Wenn Überzeugungen im Modell von \citeauthor{beisbart_making_2021} angepasst werden müssen, so funktioniert dies nach einem einfach beschriebenen Rezept:

\begin{quote}
    [...] the agent replaces her current commitments $C_i$ with those commitments $C_{i+1}$ that score best on the achievement function Z (given $T_{i+1}$).
    \autocite[S.~450]{beisbart_making_2021}
\end{quote}

Die Menge von Überzeugungen, welche (zusammen mit der aktuellen Theorie) den höchsten Wert der \textit{Achievement-Funktion} $Z$ erreicht, wird als neue Menge von Überzeugungen übernommen. Aber welche Mengen von Überzeugungen ($C^*$) stehen uns überhaupt zur Verfügung? Die Anzahl der Mengen von Überzeugungen in $C^*$ ($\lvert C^* \lvert$) ist aus der Menge an Sätzen im Thema bestimmt. Je mehr Sätze, umso mehr Mengen von Überzeugungen. Das Problem ist, dass $\lvert C^* \lvert$ exponentiell zur Zahl der Sätze im Thema wächst. Pro zwei hinzugefügte Sätze (ein Satz und dessen Negation) in einem Thema verdreifacht die Anzahl der Mengen von Überzeugungen. Das kommt daher, dass ein Satz oder seine Negation Teil einer Menge von Überzeugungen sein kann oder er ist nicht dabei. Das sind pro nicht-negiertem Satz 3 Möglichkeiten. Aus diesen Überlegungen leitet sich die Zahl der zu überprüfenden Mengen von Überzeugungen pro Anpassungsschritt ab: $\lvert C^* \rvert = 3^n$, wobei $n$ die Zahl der nicht negierten Sätze im Thema ist. Es gilt zu beachten, dass noch mehr als 3 Möglichkeiten pro neuen Satz bestehen: Es könnte ja auch der Satz und seine Negation Teil einer Menge von Überzeugungen sein. Diese Möglichkeit wird aber ausgeschlossen, da von Mengen von Überzeugungen \textit{minimale Konsistenz} gefordert wird.

Die Regel zur Anpassung einer Theorie sieht zwar analog aus, allerdings können die Sätze, welche überprüft werden müssen, etwas eingeschränkt werden.

\begin{quote}
    [...] the agent newly adopts an epistemic state $(C_i, T_{i+1})$ such that the theory $T_{i+1}$ scores best in terms of the achievement function $Z$ given $C_i$.
    \autocite[S.~450]{beisbart_making_2021}
\end{quote}

Zusätzlich schränken nun die Inferenzbeziehungen zwischen den Sätzen, die Kandidaten ein. Weil Theorien vollständig konsistent sein müssen, darf auch kein Theoriekandidat Inkonsistenzen enthalten.
Im traditionellen Ansatz werden inkonsistente Mengen vorneweg ausgeschlossen, um später nicht immer wieder einzeln die Konsistenz prüfen zu müssen. Deshalb wird vorab der Inhalt jeder möglichen Theorie ($3^n$) errechnet und abgespeichert. Alle Mengen mit Inhalten, die Widersprüche enthalten, werden ausgeschlossen. Dies bedeutet aber auch, einen zusätzlichen Mehraufwand, weil über alle möglichen Theorien iteriert werden muss.

Für eine sehr kleine Menge von Sätzen gelingt eine übersichtliche Darstellung der Theoriekandidaten noch. Bei Abbildung \ref{fig:smallset} ist eine sehr kleine Menge von Sätzen abgebildet. Wenn nun \textit{s2} die einzige Überzeugung ist und man dazu die passende Theorie suchen möchte, so würden folgende Kombinationen überprüft: $\{\{\}, s1, s2, \neg s1, \neg s2, \{s1,s2\}, \{s1,\neg s2\}, \{\neg s1, s2 \}, \{\neg s1, \neg s2 \} \}$. In dieser einfachen Struktur können keine Mengen ausgeschlossen werden. Alle 9 Elemente müssten überprüft werden. Wenn nun ein einziges weiteres Element \textit{s3} hinzukäme, müssten 27 Mengen überprüft werden. Bei einem weiteren 81. Das heisst, der Arbeitsaufwand wächst exponentiell zur Anzahl an Sätzen im System. Dies macht diese Methode unrealistisch in der Benutzung. Ausserdem ist es auffällig, wie schnell und einfach die Anpassung intuitiv gemacht werden kann. Für eine Person ist es auf einen Blick zu erkennen, dass s1 das einzige Prinzip ist, welches infrage kommt. Deshalb muss ein neuer Ansatz entwickelt werden.


\section{Der Piecemeal-Ansatz} \label{piecemealansatz}
Wie \autocite[S.461]{beisbart_making_2021} feststellten, scheint die naheliegendste und einfachste Umsetzung eines Piecemeal-Ansatzes zu sein, einzelne Überzeugungen oder Prinzipien in einer vorhandenen Theorie bzw. Menge von Überzeugungen zu ändern bzw. einzelne neue Sätze hinzuzufügen. So geht es im Piecemeal-Ansatz denn auch um die Idee, von den bestehenden Überzeugungen bzw. der bestehenden Theorie auszugehen anstatt agnostisch davon auszugehen, dass sich alle möglichen Theorien gleich gut für die Anpassung eignen. Man ändert die bestehende Theorie bzw. die bestehenden Überzeugungen um ein einzelnes Element ab und sieht, ob diese abgeänderte Theorie bzw. die abgeänderten Überzeugungen besser zu ihrem Gegenstück passen. Im Folgenden werde ich den Prozess, der zum Erreichen eines Überlegungsgleichgewichts führt und seine Einzelteile detailliert erklären.

\subsection{Der Anpassungsprozess}
Der Ablauf des Prozesses - wie aus einer dialektischen Struktur von Sätzen und einer Menge von Anfangsüberzeugungen ein Überlegungsgleichgewicht entsteht - ist im Grunde genommen nicht anders als der des traditionellen Ansatzes, nur die einzelnen Schritte sind anders definiert. In einem ersten Schritt wird der initiale epistemische Zustand definiert, der aus der ersten Theorie ($T_0$) und den initialen Überzeugungen ($C_0$) besteht. $T_0$ ist als die leere Menge ({}) festgesetzt.\footnote{Einen Vorschlag für eine bessere initiale Theorie befindet sich \hyperref[better-first-theory]{im Anhang}.} $C_0$ ist als Eingabe neben der dialektischen Struktur der Sätze gegeben. Danach wird die bestehende Theorie an die aktuellen Überzeugungen angepasst. Dabei wird die Theorie, welche die höchsten Werte der Desiderata Kohärenz und Systematizität erreicht zur neuen Theorie gewählt, wenn die Werte besser sind, als die der bestehenden Theorie. Im nächsten Schritt wird die Menge der Überzeugungen an die geänderte Theorie angepasst. Dabei wird die Menge der Überzeugungen gewählt, welche die höchsten Werte der Desiderata Kohärenz und Respekt erreicht, sofern die Werte höher sind als bei der alten Menge von Überzeugungen. Die beiden vorhergehenden Schritte werden so lange nacheinander angewendet, bis die Änderungen keine Verbesserung des Wertes der Achievement-Funktion bringt.

\subsubsection{Anpassung der Theorie} \label{T-Anpassung}
Ausgehend von einer Menge von Überzeugungen $C_i$ wird eine Theorie $T_i$ wie folgt angepasst: 
\begin{enumerate}
    \item \label{1} Alle Sätze $s$ des Themas $S$ (auch die Negationen) werden einzeln zu der Menge von Prinzipien in $T_i$ hinzugefügt, falls sie oder ihre Negationen noch nicht enthalten sind. Die Menge der daraus entstandenen Theoriekandidaten heisst $T_i^*$. Die Sätze in $S$ sind indexiert.
    $$ 
        T_i^*:= \{ T_i \cup \{s_j\}: (s_j \in \{S \setminus T_i\}) \land (\neg s_j \not\in T_i) \}
    $$
    \item \label{1.1} Jede Menge, die entsteht, wenn man einen einzelnen Satz in $T_i$ negiert wird mit $T_i^*$ vereinigt. Die daraus entstandene Menge heisst $T_i^{**}$.
    $$
        T_i^{**}:= T_i^* \cup \{ (T_i \setminus \{s_j\}) \cup \{\neg s_j\}: s_j \in T_i\}
    $$
    \item \label{2} Die Mengen, die entstehen, wenn man einzelne Prinzipien aus $T_i$ entfernt und $T_i^{**}$ werden vereinigt. Die daraus entstandene Menge heisst $T_i^{***}$.
    
    $$
        T_i^{***}:= T_i^{**} \cup \{ T_i \setminus \{s_j\}: s_j \in T_i\}
    $$
    
    \item \label{konsistenzfilter} Inkonsistente Mengen werden aus $T_i^{***}$ entfernt.(Weiteres zur Konsistenz siehe Abschnitt \ref{konsistenz})
    
    $$
        T_i^{***} \setminus \{f : f \in T_i^{***} \land f \text{ ist inkonsistent} \}
    $$
    \item \label{3} Für jedes Element der Menge $T_i^{***}$ wird der Wert der Achievement-Funktion $Z$ ermittelt.
    \item \label{4} Der Theoriekandidat, welcher den höchsten Wert bei $Z$ erreicht, wird zur Theorie $T_{i+1}$ erklärt, falls sein $Z$-Wert auch grösser ist als jener von $T_i$ - Ansonsten wird $T_i$ zu $T_{i+1}$. Falls mehrere Mengen den gleichen, höheren Wert als $C_i$ erreichen, wird zufällig eine der Mengen ausgewählt.\footnote{Dies ist möglicherweise nicht die Beste Option. Eventuell wäre es ratsamer, an dieser Stelle den RE-Prozess für alle Mengen mit den gleichen $Z$-Werten durchzuführen und somit den Prozess an dieser Stelle zu verzweigen. Das vorgestellte Modell könnte in dieser Weise angepasst werden.}
\end{enumerate}

\subsubsection{Anpassung der Überzeugungen} \label{C-Anpassung}
Ganz analog läuft die Überzeugungsanpassung an die Theorie $T_i$. Einzig Schritt \ref{konsistenzfilter} kann ausgelassen werden, da die Menge von Überzeugungen nur minimal konsistent sein muss.
\begin{enumerate}
    \item \label{c1} Alle Sätze des Themas $S$ werden einzeln zu der Menge von Überzeugungen in $C_i$ hinzugefügt, falls sie oder ihre Negationen noch nicht enthalten sind. Die Menge der daraus entstandenen Mengen von Überzeugungen heisst $C_i^*$. Die Sätze in $S$ sind indexiert.
    
    $$ 
    C_i^*:= \{ C_i \cup \{s_j\}: (s_j \in \{ S \setminus C_i \}) \land (\neg s_j \not\in C_i) \}
    $$
    
    \item \label{c1.1} Jede Menge von Sätzen, die entsteht, wenn man einen einzelnen Satz in $C_i$ negiert wird mit $C_i^*$ vereinigt. Die daraus entstandene Menge heisst $C_i^{**}$.
    
    $$
    C_i^{**}:= C_i^* \cup \{ (C_i \setminus \{c_j\}) \cup \neg c_j: c_j \in C_i\}
    $$
    
    \item \label{c2} Die Mengen, die entstehen, wenn man einzelne Überzeugungen aus $C_i$ entfernt werden mit $C_i^{**}$ vereinigt.
    
    $$
    C_i^{***}:= C_i^{**} \cup \{ C_i \setminus \{c_j\}: c_j \in C_i\}
    $$
    
    \item \label{c3} Für jedes Element der Menge $C_i^{***}$ wird der Wert der Achievement-Funktion $Z$ ermittelt.
    \item \label{c4}Die Menge von Überzeugungen, welche den höchsten Wert bei $Z$ erreicht, wird zu $C_{i+1}$ erklärt, falls ihr $Z$-Wert auch grösser ist als jener von $C_i$ - Ansonsten wird $C_i$ zu $C_{i+1}$. Falls mehrere Mengen den gleichen, höheren Wert als $C_i$ erreichen, wird zufällig eine der Mengen ausgewählt.\footnotemark[\value{footnote}]
\end{enumerate}

\subsubsection{Stoppbedingung}
Die beiden Schritte \hyperref[T-Anpassung]{Theorieanpassung} und \hyperref[C-Anpassung]{Überzeugungsanpassung} werden nacheinander abwechselnd angewendet, bis beide Schritte keine Änderung der Position mehr bringen, bis also $(C_i, T_i) = (C_{i+1}, T_{i+1})$. Wenn also bei Schritt \ref{c4} der Überzeugungsanpassung und Schritt \ref{4} der Theorieanpassung jeweils die bestehende Menge zur neuen Menge wird, weil deren $Z$-Wert höher oder gleich hoch ist, wie jener der Menge mit dem höchsten Wert im aktuellen Schritt, stoppt der Prozess des Angleichens. Dadurch wird garantiert, dass der Prozess aufhört, wenn ein Fixpunkt erreicht wurde. Die Stoppbedingung ist dieselbe wie \autocite[S. 450]{beisbart_making_2021} sie schon definiert haben.

\subsection{Aufwand}
Allgemein lässt sich sagen, dass in Schritt 1 der beiden Anpassungen immer $\lvert S \rvert - 2\lvert C_i/T_i \rvert$ Kandidaten hinzukommen. Denn wenn $C_i/T_i$ einen Satz enthält, kann er und seine Negation nicht mehr hinzugefügt werden. In Schritt 2 \& 3 kommen hingegen jeweils $\lvert C_i \rvert / \lvert T_i \rvert$ Kandidaten hinzu. Das führt dazu, dass in jedem Anpassungsschritt insgesamt $\lvert S \rvert$ Kandidaten hinzugefügt werden. Bei den Theorieanpassungen, werden allerdings nichtkonsistente Mengen wieder entfernt. Somit wächst der Aufwand für die Überprüfung der Mengen pro Schritt linear zur Mächtigkeit von $S$. Im Vergleich zum exponentiellen Wachstum im traditionellen Ansatz ist dies fast ideal. Die Frage stellt sich nur, ob die Anzahl an Schritten im piecemeal-Ansatz nicht exponentiell wächst. Dies werde ich in Abschnitt \ref{Ensemblestudie} experimentell annähern.

\subsection{Beispiel}
\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/reduced_classical.png}
  \caption{Beispielstruktur\label{fig:classset-initial1}}
\end{figure}

 Als Beispiel für den Ablauf eines Piecemeal-Prozesses kann die folgende Struktur genommen werden:
 \begin{enumerate}
     \item Die Struktur beinhaltet 5 Sätze: $\{s1,...,s5\}$
     \item Aus $s1$ folgen $s3, s4, s5$.
     \item Aus $s2$ folgen $\neg s4, s5$
 \end{enumerate}
 
 Die initialen Überzeugungen ($C_0$) definiere ich wie folgt:
 
 $C_0 = \{s3, s4, s5\}$
 
 Eingängiger ist die Struktur und die initialen Bedingungen auf Abbildung \ref{fig:classset-initial1} dargestellt.\footnote{Die Zeichen unter den Satzbezeichnungen sind wie folgt zu deuten: \textit{Position in der Theorie | Position in den Überzeugungen} Dabei steht X für: \textit{Dieser Satz kommt in der Menge nicht vor}. T für \textit{Dieser Satz ist in der Menge} und F für \textit{Die Negation des Satzes ist in der Menge.} Zusätzliche Klammern (()) können vorkommen um anzuzeigen, dass diese Position notwendig ist, um kohärent zu sein.}
 Unser initialer epistemischer Zustand $(C_0, T_0)$ ist gegeben durch die leere Menge und die oben definierten initialen Überzeugungen. Zur ersten Anpassung der Theorie - Also um $T_1$ zu finden - wird nun die initiale Theorie genommen, und ihr werden einzeln alle Sätze des Themas S hinzugefügt.
 $$
 T_0: \{\} \longrightarrow T_0^*: \{\{s1\},...,\{s5\}, \{\neg s1\}, ..., \{\neg s5\}\}
 $$
 Beim \hyperref[1.1]{zweiten Schritt} kommt keine Menge hinzu, denn in der leeren Menge gibt es keine Sätze, die negiert werden könnten. Auch beim \hyperref[2]{dritten Schritt} kommen keine neuen Sätze hinzu, denn man kann keine Sätze aus der leeren Menge entfernen. Auch im \hyperref[konsistenzfilter]{vierten Schritt} können keine Mengen entfernt werden, denn eine Menge mit einem Element kann nie inkonsistent sein. Die erste Anpassung der Theorie überprüft also einfach alle einzelnen Sätze $\{s1,...,s5, \neg s1, ..., \neg s5\}$. Derjenige, welche den höchsten Wert von $Z$ erreicht, wird zum einzigen Prinzip. Dies ist $s1$, dessen Inhalt $\{s1,s3,s4,s5,\neg s2\}$ ist. Sie erhält die meisten Punkte im Desiderat Kohärenz, denn Sie enthält alle Überzeugungen im Inhalt und keine der Überzeugungen ist inkonsistent mit der Theorie. Einzige Abzüge in der Kohärenz erhält $\{s1\}$ weil sie viele Sätze impliziert, die gar nicht Teil der Überzeugungen sind: $\{s1, \neg s2\}$ sind im Inhalt, aber nicht in den Überzeugungen. Trotzdem erreicht $\{s1\}$ den höchsten Wert bei $Z$ und wird damit zu $T_1$.
 
 Die Überzeugungen müssen als Nächstes angepasst werden. Dazu überprüfen wir die Menge von Mengen, welche $C_0$ und einen weiteren Satz enthalten.
 
 \begin{equation} \notag
 \begin{split}
 C_0^*: \{\{s3, s4, s5, \textcolor{red}{s1}\}, \{s3, s4, s5, \textcolor{red}{s2}\}, \\
 \{s3, s4, s5, \textcolor{red}{\neg s1}\}, \{s3, s4, s5, \textcolor{red}{\neg s2}\}\}
 \end{split}
 \end{equation}
 
 Im Schritt \ref{c1.1} werden dann alle Mengen erstellt, die entstehen, wenn man einzelne Sätze in $C_0$ negiert.
 
 \begin{equation} \notag
 \begin{split}
 C_0^{**}: C_0^* \cup \{\{\textcolor{red}{\neg s3}, s4, s5\}, \{s3, \textcolor{red}{\neg s4}, s5\}, \{s3, s4, \textcolor{red}{\neg s5}\}\}
 \end{split}
 \end{equation}
 
 Ausserdem überprüfen wir entsprechend Schritt \ref{c2} die Mengen, welche entstehen, wenn man einen einzelnen Satz aus $C_0$ entfernt.
 
$$
    C_0^{***}:= C_0^{**} \cup \{ \{s4,s5\}, \{s3,s5\}, \{s3,s4\} \}
$$
 
 Von all den Überzeugungsmengen in $C_0^{***}$ haben folgende 3 Mengen den gleichen Wert der Achievement-Funktion: $\{s3,s4,s5,s1\}$, $\{s3,s4,s5,\neg s2\}$. Ob man also $s1$ zu den weiteren Überzeugungen dazunimmt oder $\neg s2$ hinzunimmt, spielt für die nächste Generation keine Rolle. In allen beiden Optionen wird nämlich das Desideratum der Kohärenz etwas besser erfüllt und das Desideratum des Respekts etwas weniger gut, denn wir haben einen Satz in der Überzeugungsmenge, der nicht zur ursprünglichen Überzeugungsmenge gehört. 
Eine der beiden Möglichkeiten wird nun zufällig ausgewählt. Wir legen uns für das Beispiel fest: $C_1 = \{s3, s4, s5, \neg s2\}$
 
 Bei der zweiten Anpassung der Theorie müssen nun folgende Theoriekandidaten geprüft werden:
\begin{align}
    T_1^{*}:= &\{\{s1, s3\}, \{s1, s4\}, \{s1, s5\},\stkout{\{s1, s2\}}, \{s1, \neg s2\}, \stkout{\{s1, \neg s3\}, \{s1, \neg s4\}, \{s1, \neg s5\}}\}\\
    T_1^{**}:= T_1^{*} \cup &\{\{\neg s1\}\}\\
    T_1^{***}:= T_1^{**} \cup &\{\{\}\}
\end{align}
Die durchgestrichenen Kandidaten werden in Schritt \ref{konsistenzfilter} entfernt, weil sie inkonsistent mit $\{s1\}$ sind.
 Das Resultat ist, dass keine der überprüften Theorien besser ist als $T_1$. Somit wird $T_1$ auch zu $T_2$ übernommen.
 
 Es folgt eine weitere Anpassung der Überzeugungen. Wir erinnern uns, dass wir im letzten Anpassungsschritt die Wahl zwischen der Hinzufügung von $s1$ zu $C_0$ hatten oder der Hinzufügung von $\neg s2$. Wir hatten und zufällig für die zweite Option entschieden. Da sich die Theorie im letzten Anpassungsschritt nicht verändert hat, liegt auf der Hand, dass das Hinzufügen von $s1$ zu $C_1$ die beste Alternative sein muss. Ich überspringe an dieser Stelle also das aufzeichenn und vergleichen von $C_1^{***}$ und füge $s1$ zu $C_1$ hinzu. Somit sieht $C_2$ nun wie folgt aus: $C_2 = \{s3, s4, s5, \neg s2, s1\}$
 
 Weil $T_2$ mit $T_1$ identisch ist, müssen im nächsten Theorieanpassungsschritt um $T_3$ zu finden auch dieselben Theoriekandidaten überprüft werden. Da die Hinzufügung von $s1$ zu den Überzeugungen optimal für $T_2$ war, kann es keine Theorie geben, die besser passt. Denn wäre das der Fall, so müssten wir in einem der vorherigen Theorieanpassungsschritte eine suboptimale Theorie ausgewählt haben. Das führt mich zur Annahme, dass bei einer dialektischen Struktur mit einder Prämisse, keine weiteren Theorieanpassungsschritte unternommen werden müssen, wenn in einem Schritt keine bessere Theorie gefunden wurde. Dafür benötigt es natürlich einen Beweis oder wenigstens weitere experimentelle Hinweise, deshalb lasse ich dies als Vermutung hier stehen. Für das Beispiel lässt sich aber feststellen, dass es keine bessere Theorie als $\{s1\}$ gibt. $T_3$ ist daher $\{s1\}$.
 
 Es folgt eine letzte Überprüfung der Überzeugungen. Folgende Mengen werden überprüft:
 \begin{align}
    C_2^{*}:= &\{\}\\
    C_2^{**}:= C_2^{*} \cup &\{\{\neg s3, s4, s5, \neg s2, s1\}, \{s3, \neg s4, s5, \neg s2, s1\}, \{s3, s4, \neg s5, \neg s2, s1\},\\ \notag
    &\{s3, s4, s5, s2, s1\}, \{s3, s4, s5, \neg s2, \neg s1\}\}\\
    C_2^{***}:= C_2^{**} \cup &\{\{s3, s4, s5, \neg s2\}, \{s3, s4, s5, s1\}, \{s3, s4, \neg s2, s1\}, \{s3, s5, \neg s2, s1\},\\ \notag
    &\{s4, s5, \neg s2, s1\}\}
 \end{align}
 
 Dabei fällt auf, dass mit $C_2^{*}$ keine neuen Kandidaten gefunden werden können. Denn jeder Satz in S kommt schon (evtl. negiert) in $C_2$ vor. Dafür werden in den folgenden Schritten jeweils $\lvert S \rvert = 5$ Mengen gefunden, welche überprüft werden müssen.
 Nach dem beschriebenen Rezept wird diese wieder durchgeführt, mit dem Ergebnis, dass es keine Verbesserung gibt und $C_3$ mit $C_2$ gleichgesetzt wird. Weil bei der letzten Theorieanpassung schon keine bessere Theorie gefunden wurde, ist damit die Stoppbedingung erfüllt und der Prozess endet in einem Reflective Equilibrium.
 
 Während des Prozesses mussten in den drei Theorieanpassungsschritten 22 Theoriekandidaten (30 Kandidaten - 8 inkonsistente Mengen) überprüft werden.  Im Vergleich zum traditionellen Ansatz, bei dem in jedem Schritt $3^5$ Mengen (abzüglich der inkonsistenten Theoriekandidaten) überprüft und verglichen werden müssen. In der Anpassung der Überzeugungen im Beispiel müssen bei allen drei Anpassungen insgesamt 30 Überzeugungen überprüft werden. Beim traditionellen Ansatz müssen bei jedem Schritt wieder $3^5$ Überzeugungen überprüft werden. Wichtig für die Frage, ob der traditionelle Ansatz wirklich weniger effizient ist, ist neben der Anzahl zu überprüfenden Mengen pro Schritt auch die Anzahl der Schritte. Diese wäre für unser Beispiel für das traditionelle Modell bei beiden Anpassungen 3 Schritte, für den neuen Ansatz sind es auch je 3 Schritte. Die Anzahl Schritte ist also tatsächlich gleich hoch, aber die Anzahl von hinzugefügten Mengen pro Schritt ist $48.6$ mal tiefer im Piecemeal-Ansatz. Wenn sich bei weiteren Kompositionen ähnliche Werte ergeben, ist die neue Methode der traditionellen vorzuziehen. Ausserdem gilt es zu überprüfen, ob die Methode globale Optima erreicht. Ausserdem gibt es für piecemeal einige weitere Einschränkungen und Schwierigkeiten, auf die ich noch zu sprechen komme.

\section{Ensemblestudie} \label{Ensemblestudie}

Um zu untersuchen, wie sich der Piecemeal-Ansatz gegenüber dem Standard-Ansatz verhält, habe ich ein umfangreiches Datenset generiert und dieses analysiert. Ich werde in diesem Abschnitt kurz darauf eingehen, wie das Datenset aufgebaut ist und dann erklären, was ich untersucht habe und was die Erkenntnisse sind. Generiert wurden die Daten alle mittels einer Python-Bibliothek, wie von den Mitgliedern des Forschungsprojekts \textit{How Far Does Reflective Equilibrium Take Us?} erarbeitet wurde. Alle Grafiken in diesem Teil können als interaktive SVGs auf dieser Website abgerufen werden: \href{https://piecemeal.flicks.jetzt/}{piecemeal.flicks.jetzt}. Ich empfehle, das auch zu tun, da die Grafiken dort besser lesbar sind und bspw. die exakten Werte an der Position der Maus angezeigt werden.

\paragraph{Aufbau} Ich habe 2400 RE-Prozesse generiert. Davon sind die Hälfte Prozesse nach dem neuen Piecemeal-Ansatz und die andere Hälfte nach dem Standard-Ansatz. Angefangen bei einer Menge von fünf Sätzen im Satzpool wurden jeweils 50 zufällige Argumentstrukturen generiert und mit 2 zufällig generierten Mengen von initialen Überzeugungen kombiniert. Der Prozess wird wiederholt und diesmal werden auch Argumente mit bis zu zwei Prämissen erlaubt. Dies wurde für Poolgrössen von 5 bis 10 wiederholt, was 1200 initiale Strukturen ergibt. Alle wurden mit dem Standard-Prozess und mit dem Piecemeal-Vorschlag untersucht, was dann 2400 RE-Prozesse ergibt.

\paragraph{Anzahl der initialen Überzeugungen} Es fällt auf, dass drei Viertel der Prozesse, welche dieselben initialen Strukturen haben, unterschiedliche Fixpunkte erreichen. Wenn man davon ausgeht, dass der Standard-Ansatz eigentlich immer ein globales Optimum erreicht, würde das bedeuten, dass der Piecemeal-Ansatz in diesen Fällen bei einem Fixpunkt stehen bleibt, der einen schlechteren Wert bei der Funktion Z erreicht. Dass dies nicht unbedingt so ist, lässt sich später anhand von Grafiken zeigen. Je nachdem, wie viele initiale Überzeugungen in der initialen Struktur waren, kann der Piecemeal-Ansatz durchaus bessere Ergebnisse erreichen. Bei nur einem oder zwei initialen Überzeugungen funktioniert der Standard-Ansatz immer besser. Je höher die Zahl der Überzeugungen am Anfang des Prozesses aber wird, umso besser funktioniert auch der Piecemeal-Ansatz.

\paragraph{Übersicht} Um eine grobe Übersicht über das Ensemble zu erhalten, möchte ich die wichtigsten Kennzahlen betrachten. 52,92~\% aller Prozesse haben ein globales Optimum erreicht. Dies ist viel weniger als erwartet. Ein Grund könnte sein, dass der Piecemeal-Ansatz viel schlechter als der Standard-Ansatz funktioniert und so den Durchschnitt herunterzieht. Aufgeteilt auf die Ansätze ergeben sich aber nicht viel bessere Zahlen: 54,17~\% der standard-Prozesse und 51,67~\% der piecemeal-Prozesse haben ein globales Optimum erreicht. Wenn man vergleicht, wie oft welcher Prozess besser war, so ergibt sich ein interessantes Bild: Der Standard-Prozess hat insgesamt in 376 (31,33~\%) Fällen einen höheren Wert bei der Achievement-Funktion erreicht, als der entsprechende Piecemeal-Prozess mit derselben dialektischen Struktur und denselben initialen Überzeugungen. In 302 ($25.1\overline{6}~\%$) Fällen, hat der Piecemeal-Prozess einen höheren $Z$-Wert. In den verbleibenden 522 ($43,5~\%$) Fällen waren beide Ansätze gleich gut. Dies hat mich anfangs sehr überrascht, denn die Werte der Achievement-Funktion sind Gleitkomme-Werte oft mit mehr als 5 Stellen nach dem Komma. Die erreichten Fixpunkte der beiden Prozesse sind in $75\%$ der Fälle nicht gleich! Wie können also zwei Prozesse, mit unterschiedlichen Fixpunkten, genau denselben $Z$-Wert erreichen? Tatsächlich wurden im vorliegenden Ensemble nur 121 verschiedene Werte der Achievement-Funktion erreicht. Wobei auf die häufigsten 12 Werte mehr als die Hälfte aller Überlegungsgleichgewichts-Prozesse fallen. Damit ist es dann auch nicht weiter verwunderlich, dass in fast der Hälfte der Fälle, der gleiche Wert der Achievement-Funktion getroffen wurde.


\subsection{Entdeckte Probleme} \label{found problems}
\paragraph{Falsche Reihenfolge der Anpassungen} Der programmierte Ansatz funktioniert nicht genau wie der Prozess, den ich in Absatz \ref{piecemealansatz} definiert habe. Der wichtigste Unterschied ist folgender: Die Reihenfolge, in der die Schritte unternommen werden, ist vertauscht. Sie sieht wie folgt aus:
\begin{enumerate}
    \item $C_0$ wird definiert aus den eingegebenen Überzeugungen.
    \item $T_0$ wird als leere Menge definiert.
    \item Die Überzeugungen passen sich an die aktuelle Theorie an.
    \item Die Theorie passt sich an die aktuellen Überzeugungen an.
    \item Die beiden vorherigen Schritte werden wiederholt, bis die Stoppbedingung eintrifft.
\end{enumerate}

Diese Reihenfolge führt dazu, dass immer die Menge der Überzeugungen an die leere Menge angepasst wird. Was in jedem Fall dazu führt, dass ein zufälliger Satz aus der Menge der Überzeugungen gestrichen wird. Dies kann natürlich nur hinderlich sein. Im besten Fall führt es zu einigen zusätzlichen Anpassungsschritten, im schlechtesten Fall zu einem intuitiv nicht nachvollziehbaren Ergebnis.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/wierd.png}
  \caption{Struktur, die zu einem nicht nachvollziehbaren Ergebnis führt.\label{fig:wierd}}
\end{figure}

Betrachten wir die Struktur, die in Abbildung \ref{fig:wierd} abgebildet ist. Wenn die Menge der Überzeugungen nur ein Element enthält - wie in unserem Fall $s4$, bedeutet das, dass sich nach dem ersten Anpassungsschritt an die initiale Theorie - welche die leere Menge ist - die leere Menge auch als Überzeugungsmenge ergibt. An die leere Menge passt sich dann die leere Menge der Theorie an und wählt einen zufälligen Satz, aus dem keine anderen Sätze folgen, aus. Warum wird nicht die leere Menge beibehalten? Sie erreicht ja volle Kohärenz, denn der Inhalt enthält alle und nur die Sätze in der Überzeugungsmenge - keine. Weil die Systematizität der leeren Menge immer 0 ist und somit irgendein Satz besser ist als die leere Menge. Warum sollen aus dem Satz keine anderen Sätze folgen? Weil, wie im Absatz \ref{achievement-funktion} erklärt, es in der Kohärenz Abzüge gibt, für jeden Satz im Inhalt der Theorie, welcher nicht auch in den Überzeugungen enthalten ist. Sätze, aus denen keine anderen Sätze folgen,  enthalten im Inhalt lediglich sich selbst.
Die Überzeugungen passen sich danach wieder an den zufällig gewählten Satz an und übernehmen diesen. Das heisst, dass am Ende des Prozesses entweder $s3$, $s4$ oder $s5$ als alleiniger Satz in der Theorie und Überzeugung dastehen. Dies ist enorm kontraintuitiv.

Wie kann das Problem gelöst werden? Die eine offensichtliche Antwort lautet, dass das Programm die Reihenfolge einhält, welche ich in meinem Ansatz definiert habe. Noch wichtiger scheint mir aber, eine bessere erste Theorie als die leere Menge zu finden. Ein Ansatz dafür befindet sich im Anhang. Eine andere Möglichkeit wäre es, $T_0 := C_0$ zu setzen.

\paragraph{Strukturen mit mehr als einer Prämisse}
Obwohl in dieser Arbeit nur Grafiken eingearbeitet sind, in der dialektische Strukturen abgebildet sind, die Argumente mit nur einer Prämisse haben, ist das Modell von \citeauthor{beisbart_making_2021} ist nicht darauf beschränkt. Es ist möglich, Argumente mit vielen Prämissen einzubauen. Beispielsweise folgt dann aus Satz $s1$ und $s2$ zusammen $s3$. Aber nur aus $s1$ oder $s2$ alleine folgt s3 nicht. Das folgende Argument stellt eine solche Struktur dar:

\begin{center}
\begin{tabular}{c p{9cm}}
s1 & Alle Menschen sind sterblich.\\
s2 & Sokrates ist ein Mensch.\\\hline
C(s3) & Sokrates ist sterblich. 
\end{tabular}
\end{center}

Nun ist es zwar der Fall, dass jedes Argument mit zwei oder mehr Prämissen zu einem Argument mit einer Prämisse zusammengefasst werden kann, indem man einen neuen Satz (bspw. $s4$) aus einer Konjunktion der Prämissen bildet:

\begin{center}
\begin{tabular}{c p{9cm}}
s4 & Alle Menschen sind sterblich \textit{und} Sokrates ist ein Mensch.\\\hline
C(s3) & Sokrates ist sterblich. 
\end{tabular}
\end{center}

Aber dabei geht viel verloren, wir können uns nicht mehr auf die einzelnen Sätze in $s4$ beziehen. Und diese beispielsweise auch nicht angreifen. Argumente werden undurchsichtiger und unklarer, wenn sie auf diese Weise zusammengefasst werden.
Jedoch vermute ich, dass der Piecemeal-Ansatz wie er in dieser Arbeit definiert ist, schlechter funktioniert, mit Argumenten, die mehr als eine Prämisse haben. Zur Illustration ein neues Beispiel:

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/2prem.png}
  \caption{Einfachste Struktur mit zwei Prämissen\label{fig:2prem}}
\end{figure}

Wenn wir eine Theorie für den Satz $s3$ suchen, so können wir nur einen Satz hinzufügen. Fügen wir aber $s1$ oder $s2$ hinzu, so wird weder die Kohärenz, noch die Systematizität verbessert! Denn $s1$ alleine hat nur $s1$ im Inhalt. Gleiches gilt für $s2$. Zum Zustand, dass wir $\{s1,s2\}$ als Theorie haben, kommen wir nur über zwei Schritte, wobei der erste Schritt einer ist, der nie der bestmögliche ist. Dies führt dazu, dass bei dialektischen Strukturen mit Argumenten, die zwei Prämissen enthalten, kein globales Optimum erreicht wird. So ist zumindest meine Vermutung, die ich in der Ensembleanalyse weiter verfolgen werde. Ich kann allerdings hier noch eine Struktur zeigen, bei der der Standard-Ansatz das Optimum erreicht, während der Piecemeal-Ansatz dies nicht tut:

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/standard_better.png}
  \caption{piecemeal erreicht das globale Optimum nicht\label{fig:standard_better}}
\end{figure}

Aus dem genannten Grund kann der Piecemeal-Ansatz nie $s1$ und $s2$ in die Theorie aufnehmen und legt sich schlussendlich in der finalen Theorie auf einen einzelnen Satz in den initialen Überzeugungen fest, während der standard Ansatz schon im ersten Schritt die optimale Theorie $\{s1, s2\}$ findet und auch beibehält. Das Beispiel enthält übrigens aus einem bestimmten Grund so viele Sätze, die aus $\{s1. s2\}$ folgen. Das Desideratum der Systematizität muss entweder anders definiert werden, oder ihm muss weniger Gewicht zugestanden werden. Ich werde im nächsten Absatz weiter darauf eingehen. An dieser Stelle soll nur gesagt sein, dass die in Abbildung \ref{fig:standard_better} abgebildete Struktur ohne $s6$ nicht das gleiche globale Optimum hätte. Die globalen Optima wären jeweils ein einzelner Satz der initialen Überzeugungen als finale Überzeugung und als finale Theorie der gleiche Satz. Dies würden wir intuitiv wohl nicht als Optimum bezeichnen.

\paragraph{Kritik an der Systematizität}
Das Desideratum der Systematizität ist jenes mit dem höchsten Gewicht. Die Systematizität $S$ einer Theorie $T$ ist gemäss \autocite[S. 465]{beisbart_making_2021} wie folgt definiert:
$$
S(T) := 1- \left(\frac{\lvert T \rvert -1}{\lvert \overline{T} \rvert}\right)^2
$$

Die Anzahl der Sätze in der Theorie ($\lvert T \rvert$) - 1 geteilt durch die Anzahl an Sätzen im Inhalt der Theorie ($\lvert \overline{T} \rvert$) wird monoton fallend normalisiert. Was darauf hinausläuft, dass für Theorien mit einem Satz immer gilt, dass die Systematizität 1 ist. Sie also die volle Punktzahl bekommen. In \autocite[S.~447]{beisbart_making_2021} wird die Systematizität als die Einfachheit einer Theorie beschrieben und ein Beispiel einer Theorie gemacht, welche nur einen Satz enthält, aber im Inhalt viele Sätze hat. Diese sei eine sehr systematische Theorie. Das stimmt zwar, lenkt aber vom Fakt ab, dass es in diesem Fall egal ist, wieviele Sätze eine Theorie mit einem einzigen Prinzip im Inhalt enthält. Die Theorie erhält in jedem Fall volle Systematizität. Dies führt dazu, dass 1007 von den 1200 (84\%) zufällig generierten Kombinationen von initialen Überzeugungen mit einer dialektischen Struktur als optimale Theorie eine Theorie mit nur einem Satz haben. Da muss ich die Frage stellen, ob dieses Desiderat so richtig definiert beziehungsweise gewichtet ist.

\subsection{Erreichen des globalen Optimums}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/global_optima_standard_piecemeal.png}
  \caption{erreichen eines globalen Optimums für beide Ansätze insgesamt. (x-Achse: Gesamtmenge der Sätze, y-Achse: erreichte globale Optima in \%) \label{fig:GlobOptPoolsizeLine}}
\end{figure}

Das globale Optimum beschreibt verschiedene mögliche Kombinationen von Theorie und Überzeugungen für eine gegebene dialektische Struktur und initiale Überzeugungen, welche den Wert der Achievement-Funktion maximieren. In den meisten Fällen gibt es mehrere solcher Kombinationen. So, dass man von globalen Optima spricht. Um die globalen Optima zu finden, werden alle möglichen Kombinationen von Überzeugungen und Theorien miteinander verglichen. Messe ich das generierte Ensemble anhand der erreichten Fixpunkte und unterscheide dabei nach der Grösse der Satzmenge und den beiden Ansätzen, so erhalte ich das Bild, welches Grafik \ref{fig:GlobOptPoolsizeLine} abbildet.

Darauf ist zu erkennen, dass mit steigender Anzahl von Sätzen in der Satzmenge die Trefferquote beider Ansätze sinkt. Dies ist grundsätzlich zu erwarten. Jedoch konnten die Werte von 88\% - 95\%, wie sie \autocite[S.~455]{beisbart_making_2021} erreichten, nicht erreicht werden. Dies mag daran liegen, dass in meinem Ensemble zufällige dialektische Strukturen generiert während bei \autocite{beisbart_making_2021} die die Gewichtung der Desiderata verändert wurden und immer dieselben Strukturen untersucht wurden. Dennoch überrascht es, dass der Standard-Ansatz nie über 70\% der globalen Optima trifft.

Die beiden Linien der Grafik verlaufen - bis auf zwei Ausreisser - relativ parallel, wobei sich der Abstand zwischen den beiden Ansätzen zu verkleinern scheint. Jedoch ist das reine Spekulation, denn erstens handelt es sich um sehr wenige Datenpunkte und man müsste die Grafik für grössere Satzmengen weiter führen und zweitens gibt es die beiden Ausreisser von ca. 20\% die ich auf den Zufall schiebe. Denn schlussendlich gibt es ja pro Gesamtmenge der Sätze nur 100 verschiedene dialektische Strukturen. In der nächsten Grafik \ref{fig:GlobOptPoolsizeLineOnePrem} möchte ich nur die dialektischen Strukturen betrachten, welche nur Argumente mit einer Prämisse enthalten.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/global_optima_standard_piecemeal_1prem.png}
  \caption{erreichen eines globalen Optimums für beide Ansätze insgesamt. (x-Achse: Gesamtmenge der Sätze, y-Achse: erreichte globale Optima in \%) \label{fig:GlobOptPoolsizeLineOnePrem}}
\end{figure}

Bei Abbildung \ref{fig:GlobOptPoolsizeLineOnePrem} fällt auf, dass der Standard-Ansatz grundsätzlich etwas besser funktioniert, als in der vorherigen Abbilgung, der Piecemeal-Ansatz aber mal besser, mal schlechter funktioniert.


\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{images/global_optima_standard_piecemeal_2prem.png}
  \caption{erreichen eines globalen Optimums für beide Ansätze insgesamt. (x-Achse: Gesamtmenge der Sätze, y-Achse: erreichte globale Optima in \%) \label{fig:GlobOptPoolsizeLineTwoPrem}}
\end{figure}

In Darstellung \ref{fig:GlobOptPoolsizeLineTwoPrem} fällt auf, dass die Werte extrem nah beieinander sind. Mit einer grossen Ausnahme: Die Prozesse mit 9 verschiedenen Sätzen in der dialektischen Struktur. Bei den Piecemeal-Prozessen verändert sich der Prozentsatz der erreichten globalen Optima nur ein wenig. Beim Standard-Ansatz jedoch erreichen plötzlich nur noch 20\% der Prozesse ein globales Optimum. Der Anteil der globalen Optima mit nur einem Satz in der Theorie ist nicht höher, als bei anderen Satzgrössen. Ich werde in der folgenden Grafik die bisherigen Grafiken kombinieren, um zu sehen, ob sich weiteres herausfinden lässt.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth,height=5cm,keepaspectratio]{erreichen eines Globalen Optimums aufgeteilt nach Poolsize}
  \caption{erreichen eines globalen Optimums aufgeteilt nach Poolsize (x-Achse: Gesamtmenge der Sätze, y-Achse: erreichte globale Optima in \%) \label{fig:GlobOptPoolsize}}
\end{figure}

Um mit Grafik \ref{fig:GlobOptPoolsize} noch einmal zusammenzufassen: Der Standard-Ansatz zwar öfter ein globales Optimum erreicht, dies jedoch nur, weil er bei Argumenten mit nur einer Prämisse wesentlich besser funktioniert. So erreicht er denn bei Argumenten mit einer Prämisse und einer Poolgrösse von 5 zu 80\% das globale Optimum im Vergleich zu Argumenten mit einer Prämisse, wo es nur 56\% sind. Schaut man sich die zweiprämissigen Argumente an, so erreicht Piecemeal schon ab einer Poolgrösse von 6 öfter ein globales Optimum.

\subsection{Vergleich der Achievements zwischen den Ansätzen}

Wie gut ein Überlegungsgleichgewichts-Zustand - bzw. der erreichte Fixpunkt eines RE-Prozesses - ist, wird am Wert der Achievement-Funktion des Fixpunktes gemessen. Wenn der Piecemeal-Prozess einen höheren Achievement-Wert erreicht, so wird er in diesem Absatz als besser bezeichnet.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{höheres Achievement aufgeteilt nach initialen Commitments}
  \caption{höheres Achievement aufgeteilt nach initialen Überzeugungen (x-Achse: Anzahl an initialen Überzeugungen, y-Achse: Anteil der Strukturen mit höherem Achievement als das Pendent) \label{fig:höheres Achievement aufgeteilt nach initialen Commitments}}
\end{figure}

Auf Abbildung \ref{fig:höheres Achievement aufgeteilt nach initialen Commitments} fällt auf, dass ein Piecemeal-Prozess, der weniger als vier initiale Überzeugungen hat, praktisch nie besser ist, als der entsprechende Prozess mit derselben dialektischen Struktur. Dies lässt sich sehr gut mit der falschen Reihenfolge der Anpassungen (Abs. \ref{found problems}) und den Fakt, dass die initiale Theorie die leere Menge ist, zurückführen. Wie ich schon anhand eines Beispiels erklärt hatte, enden Piecemeal-Prozesse mit einem Satz in den initialen Überzeugungen immer mit einem mehr oder weniger zufälligen Fixpunkt. Dieser Effekt scheint sich erst ab 4 Sätzen in den initialen Überzeugungen langsam aufzuheben. Es ist also anzunehmen, dass, wenn die Reihenfolge der Anpassungen korrigiert wäre, der Piecemeal-Prozess wohl wesentlich besser funktionieren würde.

\subsubsection{zweiprämissige Strukturen}

Ich habe die Vermutung geäussert, dass der Piecemeal-Ansatz bei Strukturen, die Argumente enthalten, welche zwei oder mehr Prämissen enthalten nicht gut funktioniert. Dazu habe ich die Grafiken \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse} und \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf max 2 Prämissen} erstellt. In \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse} werden die standard und piecemeal Prozesse verglichen. Die \textcolor{teal}{hellblaue Säule} zeigt den Anteil an standard Prozessen, die ihre piecemeal-Partner im Achievement übertrafen. Die \textcolor{blue}{blaue Säule} zeigt den Anteil an Piecemeal-Prozessen an, die einen höheren Wert der Achievementfunktion erreichten. Die \textcolor{purple}{violetten Säulen} zeigen den Anteil an, bei dem beide Prozesse gleich gute Leistung gezeigt haben.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse}
  \caption{höheres Achievement aufgeteilt nach Poolsize begrenzt auf ein-Prämisse-Strukturen\label{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse}}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{höheres Achievement aufgeteilt nach Poolsize begrenzt auf max 2 Prämissen}
  \caption{höheres Achievement aufgeteilt nach Poolsize begrenzt auf 2 Prämissen-Strukturen\label{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf max 2 Prämissen}}
\end{figure}

In den Grafiken \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf eine Prämisse} und \ref{fig:höheres Achievement aufgeteilt nach Poolsize begrenzt auf max 2 Prämissen} ist nun erkennbar, dass der Piecemeal-Ansatz deutlich besser funktioniert, wenn die Argumente 2 Prämissen haben können und die Grösse des Satzpools etwas grösser ist als nur 5. Dies spricht nun stark gegen meine ursprüngliche Vermutung! Ich habe aber mehrere Faktoren ausgemacht, die das Ergebnis erklären könnten. Die meisten Entdeckungen, die ich bis zu diesem Punkt gemacht habe, spielen eine Rolle. Allen voran das Problem mit der Systematizität. Denn, 465 von 594 Strukturen mit mindestens einem Argument, das zwei Prämissen hat, haben ein globales Optimum mit nur einem Satz in der Theorie. Dies entspricht 78\% und damit etwas weniger als dem Schnitt von 83\% von allen Strukturen. Bei den Strukturen mit dialektischen Strukturen die nur einprämissige Argumente enthalten, sind es sogar 542 von 606 globalen Optima und damit 89\%, die nur einen Satz in der Theorie enthalten. Allein die Anzahl an globalen Optima mit nur einem Satz kann den Unterschied also nicht erklären. Wenn man sich weiter anschaut, in wie vielen Fällen der Standard-Ansatz einen Fixpunkt erreicht, der mehr als einen Satz in der Theorie enthält, so sind dies bei ein-Prämisse-Strukturen 106, bei den Zwei-Prämissen-Strukturen allerdings 228. In all diesen Fällen kann das Optimum nicht erreicht worden sein. Piecemeal-Prozesse erreichen in ein-Prämissen-Strukturen 35 Mal eine Theorie mit mehr als einem Satz, bei zwei-Prämissen-Strukturen sind es sogar nur 9 Mal. Zwar erreichen auch 189 der 465 betrachteten piecemeal Prozesse das Globale Optimum nicht, aber trotzdem erklärt dies, die besseren Achievmentwerte sehr gut. Ich schliesse aus dem Genannten, dass der Standard-Ansatz bei Ein-Prämisse-Strukturen eher Lösungen generiert, die mehr als einen Satz in der Theorie haben und deswegen schlechter funktioniert als bei Zwei-Prämissen-Strukturen im Vergleich mit Piecemeal-Prozessen. Aber warum erreichen Piecemeal-Prozesse konsequent Theorien mit nur einem Satz?

\paragraph{leere Anfangstheorie} Dadurch, dass im Piecemeal-Ansatz die initiale Theorie als leere Menge definiert ist und jeweils nur ein Satz dazu kommt, ist garantiert, dass jeder piecemeal Prozess mindestens einmal im Verlauf des Prozesses eine Theorie mit einem Satz hat. Der in Abschnitt \ref{found problems} beschriebene Fehler in der Reihenfolge der Anwendung im Programm dürfte ausserdem hilfreich sein, auf eine Theorie mit nur einem Satz zu kommen und dabei zu bleiben. Denn dadurch wird ja ein zufälliger Satz der Überzeugungen entfernt und aus weniger Überzeugungen folgt auch, dass eher weniger Sätze in der Theorie sind.

\section{Fazit}
Das anwendbare Modell des Überlegungsgleichgewichts von \citeauthor{beisbart_making_2021} treibt die philosophische Arbeit in diesem Bereich ein grosses Stück voran. Ich hoffe, mit meiner Arbeit einen kleinen Teil beigetragen zu haben. Ich habe gezeigt, dass das Problem des Aufwands des klassischen Ansatzes des Überlegungsgleichgewichts besteht. Dieser ist nämlich so gross, dass es einerseits für Personen kaum nachvollziehbar ist, dies selbst zu tun. Andererseits ist er selbst für Computer bei komplexeren dialektischen Strukturen schnell nicht mehr anwendbar. Eine Lösung könnte der Piecemeal-Ansatz sein. Ich habe eine Version davon ausformuliert und klar definiert. Danach habe ich auch bei ihm einige Schwächen aufgezeigt. Vor allem, dass bei Argumenten, die mehr als eine Prämisse haben, Schwierigkeiten entstehen werden, scheint mir das grösste Problem. Denn um dies zu beheben, muss man davon abrücken, nur einen einzelnen Satz hinzuzufügen beziehungsweise zu entfernen. Dies würde dann aber nicht mehr dem Gedanken entsprechen, den \autocite{goodman_fact_1983} im Sinn hatte, als er über piecemeal sprach. Des Weiteren bleibt auch noch die Frage der Anfangstheorie in einem Piecemeal-Ansatz offen. Ich glaube gezeigt zu haben, dass die leere Theorie nicht die beste Methode ist. Ob aber der Vorschlag im Anhang offen ist, wird sich eventuell in Zukunft zeigen.
Das grösste Problem hat sich aber in der Festlegung und Gewichtung des Desideratums der Systematizität eröffnet. Ich habe gezeigt, dass der Status Quo bei nicht allzu weit hergeholten dialektischen Strukturen nicht intuitiv nachvollziehbare Ergebnisse liefert. Dies stellt aber überhaupt die Gewichtung und Definition der Desiderata infrage. Klar ist, dass die Desiderate in \autocite{beisbart_making_2021} nicht einfach aus der Luft gegriffen sind, sondern die Arbeit vieler Philosophen und Philosophinnen in die Festlegung geflossen ist. Wird es eventuell nie möglich sein, Desiderata zu entwerfen, die in allen Strukturen nachvollziehbare globale Optima liefern?

Das Feld des Überlegungsgleichgewichts ist weit geöffnet und es bieten sich für Philosophen und Philosophinnen Möglichkeiten, weitere Erkenntnisse zu gewinnen. Vielleicht wird es in nicht allzuferner Zukunft möglich sein, eine dialektische Struktur für eine reelle philosophische Debatte - beispielsweise mit \href{https://argdown.org/}{Argdown} - abzubilden und danach mittels Software auf eingegebene initiale Überzeugungen analysieren zu lassen und ein Überlegungsgleichgewicht vorschlagen zu lassen. Dies würde eventuell einige Diskussionen anregen und Philosophinnen und Philosophen neue Erkenntnisse und Ideen bringen.


\newpage
\printbibliography

\newpage

\section{Anhang}
\subsection{ Vorschlag für eine erste Theorie: Analyse der Inferenzbeziehungen} \label{better-first-theory}
Im traditionellen Ansatz wird im initialen Zustand die leere Menge als erste Theorie angenommen. Ich möchte einen alternativen Vorschlag vorstellen, wie eine erste Theorie gefunden werden könnte. Er entstand durch die Überlegung, wie Personen den Prozess wohl intuitiv durchführen würden. Die Idee ist, dass man sich die Inferenzbeziehungen der Argumente anschaut, welche die ersten Überzeugungen beinhalten. Aufgrund der Inferenzbeziehungen zwischen Sätzen, kann klug entschieden werden, welche Sätze sich eher als Theorien lohnen. Es gilt zu beachten, dass bei der Analyse der Inferenzbeziehungen ignoriert wird, dass Sätze auch Prinzip für sich selbst sein können. Dies dürfte aber kein Problem sein bei der Erstellung einer ersten Theorie.

\paragraph{Generierung der Theorie}
Ausgehend von der Menge von Überzeugungen $C_0$ wird eine Theorie $T_0$ wie folgt erzeugt. Wann immer eine Menge mit Subskript angegeben wird, ist damit der Wert in der Menge mit dem Index des Subskripts gemeint.
\begin{enumerate}
    \item Zu Beginn des Prozesses hat der Index $z$ - welchen wir benötigen werden um durch die Mengen in $P$ zu iterieren - den Wert Null. Und die Menge $S$ - welche unsere Theoriekandidaten enthält - entspricht am Anfang der leeren Menge. $S = \{\}$ $z = 0$
    \item Die Menge $P$ wird aus $C_0$ generiert. Sie enthält die alle Permutationen von $C_0$. $P$ ist indexiert.
    $$
        P := \{ M_i : M_i \text{ ist eine Permutation von } P\}
    $$
    \item \label{i1} Die erste Überzeugung aus der Menge in $P_z$ wird ausgewählt: $a = 0$ (Index 0)
    \item \label{i2} Falls die Menge $S_z$ leer ist: Für die aktuell ausgewählte Überzeugung $P_z^a$ werden alle Prinzipien gesucht, aus welchen die ausgewählte Überzeugung folgt. Jedes gefundene Prinzip eröffnet eine neue Menge und diese Mengen werden $S_z$ hinzugefügt. Falls $S_z$ nicht leer ist: Jedes für $P_z^a$ gefundene Prinzip wird zu den Mengen in $S_z$ hinzugefügt, falls die entstehende Menge konsistent ist und das Prinzip nicht schon enthalten ist.
    \item \label{i3} Falls $P_z^a$ noch nicht das letzte Element aus $P_z$ ist, wird die nächste Überzeugung aus $P_z$ ausgewählt (indem a um Eins inkrementiert wird) und zu Schritt \ref{i2} gesprungen.
    $$
        a = a + 1
    $$
    \item \label{i4} Falls $z < \lvert C_i \rvert!$ : $z$ wird um eins inkrementiert: $z = z + 1$ und zu Schritt \ref{i1} gesprungen.
    \item \label{i5} In den Mengen $S$ werden die Mengen, welche die gleichen Elemente enthalten, zu einer reduziert. Alle $S$ Mengen werden mittels Achievement-Funktion $Z$ überprüft.
    \item \label{i6} Die Theorie, welche den höchsten Wert bei $Z$ erreicht, wird zur Theorie $T_0$. Falls mehrere Theorien den höchsten Wert erreichen, wird eine Theorie zufällig ausgewählt.
\end{enumerate}

\paragraph{Beispiel}
Beispielhaft kann auch hier wieder die Struktur, welche auf Abbildung \ref{fig:classset-initial1} illustriert ist, dienen. Im ersten Schritt wählen wir $s3$ und finden $s1$ als mögliches Prinzip für $s3$ im zweiten Schritt. Da $S_0$ noch leer ist, fügen wir $s1$ hinzu. Dann suchen wir ein Prinzip für $s4$, wobei wir wieder auf $s1$ stossen und dieses nicht ein zweites Mal zu $S_0$ hinzufügen. Danach folgt unsere nächste und letzte Überzeugung $s5$. Für $s5$ finden wir nun zwei mögliche Prinzipien: $s1$ und $s2$. Nun ergäben sich zwei Mengen in $S_0$: $\{s1\}$ und $\{s1, s2\}$. Da $\{s1, s2\}$ aber inkonsistent ist, wird sie weggelassen. Als Nächstes starten wir den Prozess erneut, diesmal fangen wir aber mit $s4$ als erster Überzeugung an, für die wir Prinzipien suchen. Der Prozess verläuft analog zum ersten Durchgang, und am Ende haben wir eine Menge $S_1 = \{s1\}$. Für den dritten und letzten Durchgang mit $s5$ als Startüberzeugung ergibt sich aber ein anderes Bild: Zu $S_2$ werden die beiden Prinzipien $s1$ und $s2$ als einzelne Elemente hinzugefügt. Bei der Suche nach einem Prinzip für $s4$ und analog für $s3$ wird jeweils $s1$ gefunden. Zur ersten Menge in $S_2$ wird $s1$ nicht hinzugefügt, weil es schon darin ist, zur zweiten Menge nicht, weil die resultierende Menge $\{s1,s2\}$ inkonsistent wäre. Somit ist $S_1 = \{{s1}, {s2}\}$. Die Mengen in $S_0$, $S_1$ und $S_3$ werden nun zusammengeführt, wobei die Doppelungen wieder gestrichen werden können. Somit ergeben sich folgende Kandidaten, für die ihr $Z$-Wert verglichen werden muss: $\{\{s1\}, \{s2\}\}$.

\paragraph{Aufwand}
Da alle Permutationen von $C_0$ durchlaufen werden müssen, umfasst die Methode relativ viele Schritte. Allerdings gäbe es vielleicht eine Möglichkeit, nicht über alle Permutationen iterieren zu müssen und beispielsweise nur mit jedem Element aus $C_0$ einmal anzufangen. Dies bedarf aber weiterer Forschung und ist nicht Gegenstand dieser Arbeit.

\end{document}


%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{piecemeal Inferenzanalyse}

Eine interessante Alternative zur Inferenzanalyse ist die Idee, die Anpassung der Theorie auch schrittweise zu machen. Dies würde einerseits einen weiteren piecemeal-Aspekt umsetzen und andererseits das Problem der Notwendigkeit der Permutation der Überzeugungen lösen. Die Theorieanpassung würde wie folgt aussehen:

\begin{enumerate}
    \item Die erste Überzeugung aus $C_i$ wird ausgewählt: $c_a = c_0$ (Index 0)
    \item Für die ausgewählte Überzeugung $c_a$ werden alle Prinzipien gesucht, welche die ausgewählte Überzeugung zum Inhalt haben. Jedes gefundene Prinzip wird $S$ hinzugefügt, wenn es nicht schon in der Menge enthalten ist.
    \item Falls $c_x$ noch nicht das letzte Element aus $C_i$ ist, wird die nächste Überzeugung aus $C_i$ ausgewählt und zu Schritt \ref{i2} gesprungen.
    \item Aus den Elementen in $S$ werden alle konsistenten Mengen gebildet.
    \item Diese Mengen werden mittels Achievement-Funktion $Z$ überprüft.
    \item Die Theorie, welche den höchsten Wert bei $Z$ erreicht, wird zu $T_{i+1}$ erklärt, falls ihr $Z$-Wert auch grösser ist als jener von $T_i$ - Ansonsten wird $T_i$ zu $T_{i+1}$.
\end{enumerate}


\begin{enumerate}
    \item How can logic be defined in a general way, so that different rival theories can be understood as \textit{logical} theories?
\end{enumerate}

\begin{quote}
    An argument is logically valid just when conditional [sic.], with the conjunction of the premises as antecendent and the conclusion as consequent, is logically true. We can readily slip from one notion to the other[...] \cite[p.~13]{beallrestall}
\end{quote}

\subsection{Debating on logic}\label{sec:debating}
\footnote{An extensive discussion of trivialism and why it is an irrational view can be found in chapter 3 of \citeA{priest2}.}

 \fullciteauthor{beallrestall}

(see section \ref{principle:GGTP}, page \pageref{principle:GGTP})

\begin{center}
\begin{tabular}{c p{9cm}}
P1 & If I am king of France, I'm not king of France.\\\hline
C & If I am king of France, God exists. 
\end{tabular}
\end{center}

\paragraph{Systematicity} To define the consequence relation by specifying it for each argument separately would be a very unsystematic procedure. \textbf{Systematicity}, like the one brought forward by \citeauthor{resnik0} or \citeauthor{peregrinsvoboda}. They have, as I will argue, a problematic understanding of the purpose of an RE-process.